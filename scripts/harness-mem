#!/bin/bash
# Unified Harness Memory helper CLI.
#
# Usage:
#   scripts/harness-mem setup [--project <path>] [--platform <all|codex|opencode|claude|cursor|antigravity|comma-list>] [--skip-start] [--skip-smoke] [--skip-quality]
#   scripts/harness-mem doctor [--project <path>] [--platform <all|codex|opencode|claude|cursor|antigravity|comma-list>] [--fix]
#   scripts/harness-mem smoke [--project <path>]
#   scripts/harness-mem uninstall [--project <path>] [--platform <all|codex|opencode|claude|cursor|antigravity|comma-list>] [--purge-db]
#   scripts/harness-mem versions [--project <path>]
#   scripts/harness-mem import-claude-mem --source <claude_mem.db> [--dry-run] [--import-project <name>]
#   scripts/harness-mem verify-import --job <job_id>
#   scripts/harness-mem cutover-claude-mem --job <job_id> --stop-now

set -euo pipefail
IFS=$'\n\t'

SCRIPT_SOURCE="${BASH_SOURCE[0]}"
while [ -L "$SCRIPT_SOURCE" ]; do
  SCRIPT_SOURCE_DIR="$(cd -P "$(dirname "$SCRIPT_SOURCE")" && pwd)"
  SCRIPT_TARGET="$(readlink "$SCRIPT_SOURCE")"
  if [[ "$SCRIPT_TARGET" != /* ]]; then
    SCRIPT_SOURCE="${SCRIPT_SOURCE_DIR}/${SCRIPT_TARGET}"
  else
    SCRIPT_SOURCE="$SCRIPT_TARGET"
  fi
done
SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_SOURCE")" && pwd)"
SOURCE_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
HARNESS_ROOT="$SOURCE_ROOT"

TARGET_DIR="${HARNESS_MEM_TARGET_DIR:-$PWD}"
PLATFORM="all"
PLATFORM_EXPLICIT=0
BACKEND_MODE=""
UI_LANG="${HARNESS_MEM_LANG:-ja}"
SETUP_INTERACTIVE_PROMPT_USED=0
SETUP_IMPORT_CLAUDE_MEM=0
SETUP_STOP_CLAUDE_MEM_AFTER_IMPORT=0
SETUP_AUTO_UPDATE_OPT_IN=-1
FIX_MODE=0
JSON_OUTPUT=0
PURGE_DB=0
SKIP_START=0
SKIP_SMOKE=0
SKIP_QUALITY=0
QUIET=0
IMPORT_SOURCE=""
IMPORT_JOB_ID=""
IMPORT_PROJECT=""
IMPORT_DRY_RUN=0
STOP_NOW=0
VERSION_CHECK_IN_SETUP=1
AUTO_UPDATE_PACKAGE="${HARNESS_MEM_NPM_PACKAGE:-@chachamaru127/harness-mem}"
AUTO_UPDATE_CHANNEL="${HARNESS_MEM_AUTO_UPDATE_CHANNEL:-latest}"
AUTO_UPDATE_CHECK_INTERVAL_SEC="${HARNESS_MEM_AUTO_UPDATE_INTERVAL_SEC:-86400}"

MEM_HOST="${HARNESS_MEM_HOST:-127.0.0.1}"
MEM_PORT="${HARNESS_MEM_PORT:-37888}"
STATE_DIR="${HARNESS_MEM_HOME:-$HOME/.harness-mem}"
DB_PATH="${HARNESS_MEM_DB_PATH:-$STATE_DIR/harness-mem.db}"
VERSIONS_DIR="${STATE_DIR}/versions"
VERSIONS_SNAPSHOT_PATH="${VERSIONS_DIR}/tool-versions.json"
VERSIONS_HISTORY_PATH="${VERSIONS_DIR}/tool-versions-history.jsonl"
AUTO_UPDATE_STATE_PATH="${STATE_DIR}/runtime/auto-update-state.json"

BEGIN_CODEX_NOTIFY="# >>> harness-mem codex notify"
END_CODEX_NOTIFY="# <<< harness-mem codex notify"
BEGIN_CODEX_MCP="# >>> harness-mem codex mcp"
END_CODEX_MCP="# <<< harness-mem codex mcp"

usage() {
  cat <<'EOF'
Unified Harness Memory helper

Commands:
  setup      Configure Codex/OpenCode/Cursor/Claude wiring, start daemon, run smoke and quality checks.
  doctor     Validate wiring and daemon health (optionally repair with --fix).
  versions   Snapshot local/upstream versions for Codex/OpenCode/Cursor/Claude/Antigravity.
  smoke      Run isolated daemon smoke test against record/search privacy flow.
  uninstall  Remove memory wiring and optionally purge local memory DB.
  import-claude-mem          One-shot import from Claude-mem SQLite into harness-mem.
  verify-import              Verify imported data quality/privacy checks by job id.
  cutover-claude-mem         Stop Claude-mem only after verify passed.
  migrate-from-claude-mem    1-command migration: import -> verify -> cutover from Claude-mem.
  rollback-claude-mem        Rollback: restart Claude-mem and re-enable LaunchAgent.
  promote                    Promote backend mode: local → hybrid → managed.
  rollback                   Rollback backend mode to local.

Common options:
  --project <path>      Target project path (default: current directory)
  --platform <value>    all|codex|opencode|claude|cursor|antigravity or comma list (default: all)
                        examples: codex,cursor  /  opencode,cursor
  --source <path>       Source SQLite path for import-claude-mem
  --job <job_id>        Import job id for verify/cutover
  --import-project <s>  Override project name on import
  --dry-run             Plan import without writing events
  --stop-now            Required by cutover-claude-mem to actually stop Claude-mem
  --skip-version-check  Skip automatic version snapshot at end of setup/doctor
  --quiet               Reduce logs

Command options:
  setup:
    --skip-start        Do not start daemon
    --skip-smoke        Do not run smoke test
    --skip-quality      Do not run search quality test
    (no --platform)     Interactive setup prompt:
                        1) language (Japanese/English)
                        2) target tools (multi-select)
                        3) import from Claude-mem (yes/no)
                        4) stop Claude-mem after import (yes/no)
                        5) enable auto-update opt-in (yes/no)
  doctor:
    --fix               Attempt to repair missing wiring
    --json              Output structured JSON result
  uninstall:
    --purge-db          Remove ~/.harness-mem/harness-mem.db after stop
  versions:
    no additional options
EOF
}

log() {
  if [ "$QUIET" -eq 1 ]; then
    return
  fi
  echo "[harness-mem] $*"
}

warn() {
  if [ "$QUIET" -eq 1 ]; then
    return
  fi
  echo "[harness-mem][warn] $*" >&2
}

fail() {
  echo "[harness-mem][error] $*" >&2
  exit 1
}

# --- Backend config management ---
CONFIG_PATH="${STATE_DIR}/config.json"

ensure_config() {
  mkdir -p "$STATE_DIR"
  if [ ! -f "$CONFIG_PATH" ]; then
    cat > "$CONFIG_PATH" <<'CONF'
{
  "backend_mode": "local",
  "managed": {
    "endpoint": "",
    "api_key": ""
  },
  "auto_update": {
    "enabled": false,
    "package_name": "@chachamaru127/harness-mem",
    "channel": "latest"
  }
}
CONF
  fi
}

read_backend_mode() {
  ensure_config
  local mode
  mode="$(jq -r '.backend_mode // "local"' "$CONFIG_PATH" 2>/dev/null || echo "local")"
  case "$mode" in
    local|managed|hybrid) echo "$mode" ;;
    *) echo "local" ;;
  esac
}

write_backend_mode() {
  local new_mode="$1"
  ensure_config
  local tmp="${CONFIG_PATH}.tmp.$$"
  jq --arg m "$new_mode" '.backend_mode = $m' "$CONFIG_PATH" > "$tmp" && mv "$tmp" "$CONFIG_PATH"
}

read_managed_endpoint() {
  ensure_config
  jq -r '.managed.endpoint // ""' "$CONFIG_PATH" 2>/dev/null || echo ""
}

read_managed_api_key() {
  ensure_config
  jq -r '.managed.api_key // ""' "$CONFIG_PATH" 2>/dev/null || echo ""
}

read_auto_update_enabled() {
  ensure_config
  local value
  value="$(jq -r '.auto_update.enabled // false' "$CONFIG_PATH" 2>/dev/null || echo "false")"
  case "$value" in
    true|1|yes|on) echo "1" ;;
    *) echo "0" ;;
  esac
}

write_auto_update_enabled() {
  local enabled="$1"
  local enabled_json
  if [ "$enabled" -eq 1 ]; then
    enabled_json="true"
  else
    enabled_json="false"
  fi

  ensure_config
  local tmp="${CONFIG_PATH}.tmp.$$"
  jq \
    --argjson enabled "$enabled_json" \
    --arg package_name "$AUTO_UPDATE_PACKAGE" \
    --arg channel "$AUTO_UPDATE_CHANNEL" \
    '
      .auto_update = ((.auto_update // {}) + {
        enabled: $enabled,
        package_name: $package_name,
        channel: $channel
      })
    ' "$CONFIG_PATH" > "$tmp" && mv "$tmp" "$CONFIG_PATH"
}

fetch() {
  local url="$1"
  local out="$2"
  curl -fsSL --compressed "$url" -o "$out"
}

abs_dir() {
  local input="$1"
  if [ -d "$input" ]; then
    (cd "$input" && pwd)
    return
  fi
  fail "Directory not found: $input"
}

parse_options() {
  while [ "$#" -gt 0 ]; do
    case "$1" in
      --project)
        shift
        [ "$#" -gt 0 ] || fail "--project requires a path"
        TARGET_DIR="$1"
        ;;
      --platform)
        shift
        [ "$#" -gt 0 ] || fail "--platform requires a value"
        PLATFORM="$1"
        PLATFORM_EXPLICIT=1
        ;;
      --fix)
        FIX_MODE=1
        ;;
      --json)
        JSON_OUTPUT=1
        QUIET=1
        ;;
      --purge-db)
        PURGE_DB=1
        ;;
      --skip-start)
        SKIP_START=1
        ;;
      --skip-smoke)
        SKIP_SMOKE=1
        ;;
      --skip-quality)
        SKIP_QUALITY=1
        ;;
      --quiet)
        QUIET=1
        ;;
      --skip-version-check)
        VERSION_CHECK_IN_SETUP=0
        ;;
      --source)
        shift
        [ "$#" -gt 0 ] || fail "--source requires a path"
        IMPORT_SOURCE="$1"
        ;;
      --job)
        shift
        [ "$#" -gt 0 ] || fail "--job requires a value"
        IMPORT_JOB_ID="$1"
        ;;
      --import-project)
        shift
        [ "$#" -gt 0 ] || fail "--import-project requires a value"
        IMPORT_PROJECT="$1"
        ;;
      --backend)
        shift
        [ "$#" -gt 0 ] || fail "--backend requires a value (local|managed|hybrid)"
        case "$1" in
          local|managed|hybrid) BACKEND_MODE="$1" ;;
          *) fail "--backend must be one of: local, managed, hybrid" ;;
        esac
        ;;
      --dry-run)
        IMPORT_DRY_RUN=1
        ;;
      --stop-now)
        STOP_NOW=1
        ;;
      -h|--help)
        usage
        exit 0
        ;;
      *)
        fail "Unknown option: $1"
        ;;
    esac
    shift
  done
}

csv_has_value() {
  local csv="$1"
  local needle="$2"
  local item
  IFS=',' read -r -a items <<<"$csv"
  for item in "${items[@]}"; do
    local normalized
    normalized="$(printf '%s' "$item" | xargs)"
    if [ "$normalized" = "$needle" ]; then
      return 0
    fi
  done
  return 1
}

csv_append_unique() {
  local csv="$1"
  local value="$2"
  if [ -z "$csv" ]; then
    printf '%s' "$value"
    return
  fi
  if csv_has_value "$csv" "$value"; then
    printf '%s' "$csv"
    return
  fi
  printf '%s,%s' "$csv" "$value"
}

normalize_ui_lang() {
  case "$UI_LANG" in
    en|EN|english|English)
      UI_LANG="en"
      ;;
    *)
      UI_LANG="ja"
      ;;
  esac
}

ui_is_en() {
  [ "$UI_LANG" = "en" ]
}

should_prompt_platform_selection() {
  local command="$1"
  if [ "$command" != "setup" ]; then
    return 1
  fi
  if [ "$PLATFORM_EXPLICIT" -eq 1 ]; then
    return 1
  fi
  if [ "${HARNESS_MEM_NON_INTERACTIVE:-0}" = "1" ]; then
    return 1
  fi
  if [ -t 0 ] || [ "${HARNESS_MEM_FORCE_PLATFORM_PROMPT:-0}" = "1" ]; then
    return 0
  fi
  return 1
}

prompt_platform_selection() {
  local input choices token selected valid
  while true; do
    if ui_is_en; then
      cat <<'EOF'
[harness-mem] Select setup targets (multiple allowed)
  1) codex     (global: ~/.codex/config.toml)
  2) cursor    (global: ~/.cursor/hooks.json + ~/.cursor/mcp.json)
  3) opencode  (global: ~/.config/opencode/opencode.json)
  4) claude    (global: ~/.claude.json mcpServers)
  5) antigravity (experimental workspace scanning)
  a) all
Example: 1,2   (Enter=1,2)
EOF
    else
      cat <<'EOF'
[harness-mem] setup 対象を選択してください（複数可）
  1) codex     (global: ~/.codex/config.toml)
  2) cursor    (global: ~/.cursor/hooks.json + ~/.cursor/mcp.json)
  3) opencode  (global: ~/.config/opencode/opencode.json)
  4) claude    (global: ~/.claude.json mcpServers)
  5) antigravity (experimental workspace scanning)
  a) all
入力例: 1,2   (Enter=1,2)
EOF
    fi
    printf "> "
    read -r input || input=""
    input="$(printf '%s' "$input" | tr -d '[:space:]')"

    if [ -z "$input" ]; then
      PLATFORM="codex,cursor"
      log "Selected platforms: $PLATFORM"
      return
    fi

    case "$input" in
      a|A|all|ALL)
        PLATFORM="all"
        log "Selected platforms: $PLATFORM"
        return
        ;;
    esac

    selected=""
    valid=1
    IFS=',' read -r -a choices <<<"$input"
    for token in "${choices[@]}"; do
      case "$token" in
        1|codex)
          selected="$(csv_append_unique "$selected" "codex")"
          ;;
        2|cursor)
          selected="$(csv_append_unique "$selected" "cursor")"
          ;;
        3|opencode)
          selected="$(csv_append_unique "$selected" "opencode")"
          ;;
        4|claude)
          selected="$(csv_append_unique "$selected" "claude")"
          ;;
        5|antigravity)
          selected="$(csv_append_unique "$selected" "antigravity")"
          ;;
        *)
          if ui_is_en; then
            warn "Invalid selection: ${token}. Use 1,2,3,4,5 or a"
          else
            warn "無効な選択: ${token}。1,2,3,4,5 または a を入力してください"
          fi
          valid=0
          ;;
      esac
    done

    if [ "$valid" -eq 1 ] && [ -n "$selected" ]; then
      PLATFORM="$selected"
      log "Selected platforms: $PLATFORM"
      return
    fi
  done
}

prompt_language_selection() {
  local input
  while true; do
    cat <<'EOF'
[harness-mem] 言語を選択してください / Select language
  1) 日本語
  2) English
入力例: 1   (Enter=1)
EOF
    printf "> "
    read -r input || input=""
    input="$(printf '%s' "$input" | tr -d '[:space:]')"
    case "$input" in
      ""|1|ja|JA|jp|JP|japanese|Japanese)
        UI_LANG="ja"
        log "言語を日本語に設定しました"
        return
        ;;
      2|en|EN|english|English)
        UI_LANG="en"
        log "Language set to English"
        return
        ;;
      *)
        warn "Invalid selection: ${input}. Use 1 or 2"
        ;;
    esac
  done
}

prompt_yes_no_default_no() {
  local question="$1"
  local answer=""
  while true; do
    printf "%s [y/N]: " "$question"
    read -r answer || answer=""
    answer="$(printf '%s' "$answer" | tr -d '[:space:]')"
    if [ -z "$answer" ]; then
      return 1
    fi
    case "$answer" in
      y|Y|yes|YES|Yes)
        return 0
        ;;
      n|N|no|NO|No)
        return 1
        ;;
      *)
        if ui_is_en; then
          warn "Invalid input: ${answer}. Use y or n"
        else
          warn "無効な入力: ${answer}。y または n を入力してください"
        fi
        ;;
    esac
  done
}

should_prompt_setup_migration_selection() {
  local command="$1"
  if [ "$command" != "setup" ]; then
    return 1
  fi
  if [ "$SETUP_INTERACTIVE_PROMPT_USED" -ne 1 ]; then
    return 1
  fi
  return 0
}

prompt_setup_migration_selection() {
  local import_question stop_question
  if ui_is_en; then
    import_question="Import existing data from Claude-mem?"
    stop_question="Stop Claude-mem after import completes?"
  else
    import_question="Claude-memから既存データをインポートしますか?"
    stop_question="インポート完了後にClaude-memを停止しますか?"
  fi

  if prompt_yes_no_default_no "$import_question"; then
    SETUP_IMPORT_CLAUDE_MEM=1
    if prompt_yes_no_default_no "$stop_question"; then
      SETUP_STOP_CLAUDE_MEM_AFTER_IMPORT=1
    fi
  fi

  log "Migration options: import_claude_mem=${SETUP_IMPORT_CLAUDE_MEM}, stop_after_import=${SETUP_STOP_CLAUDE_MEM_AFTER_IMPORT}"
}

should_prompt_setup_auto_update_selection() {
  local command="$1"
  if [ "$command" != "setup" ]; then
    return 1
  fi
  if [ "$SETUP_INTERACTIVE_PROMPT_USED" -ne 1 ]; then
    return 1
  fi
  return 0
}

prompt_setup_auto_update_selection() {
  local auto_update_question
  if ui_is_en; then
    auto_update_question="Enable opt-in automatic updates for harness-mem?"
  else
    auto_update_question="harness-mem の自動更新（opt-in）を有効化しますか?"
  fi

  if prompt_yes_no_default_no "$auto_update_question"; then
    SETUP_AUTO_UPDATE_OPT_IN=1
    log "Auto-update opt-in: enabled"
  else
    SETUP_AUTO_UPDATE_OPT_IN=0
    log "Auto-update opt-in: disabled"
  fi
}

is_platform_enabled() {
  local target="$1"
  local entry
  IFS=',' read -r -a entries <<<"$PLATFORM"
  for entry in "${entries[@]}"; do
    local normalized
    normalized="$(printf '%s' "$entry" | xargs)"
    [ -z "$normalized" ] && continue
    if [ "$normalized" = "all" ] || [ "$normalized" = "$target" ]; then
      return 0
    fi
  done
  return 1
}

validate_platform_selection() {
  local entry
  local seen=0
  IFS=',' read -r -a entries <<<"$PLATFORM"
  for entry in "${entries[@]}"; do
    local normalized
    normalized="$(printf '%s' "$entry" | xargs)"
    [ -z "$normalized" ] && continue
    case "$normalized" in
      all|codex|opencode|claude|cursor|antigravity)
        seen=1
        ;;
      *)
        fail "Invalid --platform entry: ${normalized} (allowed: all,codex,opencode,claude,cursor,antigravity)"
        ;;
    esac
  done
  [ "$seen" -eq 1 ] || fail "Invalid --platform: ${PLATFORM}"
}

require_cmd() {
  local name="$1"
  if ! command -v "$name" >/dev/null 2>&1; then
    fail "Required command not found: $name"
  fi
}

should_use_stable_runtime_root() {
  case "$SOURCE_ROOT" in
    */.npm/_npx/*)
      return 0
      ;;
  esac
  return 1
}

sync_to_stable_runtime_root() {
  local runtime_root="${STATE_DIR}/runtime/harness-mem"

  mkdir -p "${STATE_DIR}/runtime"

  if check_cmd rsync; then
    rsync -a --delete --exclude '.git' "${SOURCE_ROOT}/" "${runtime_root}/"
  else
    rm -rf "${runtime_root}"
    mkdir -p "${runtime_root}"
    cp -R "${SOURCE_ROOT}/." "${runtime_root}/"
    rm -rf "${runtime_root}/.git"
  fi

  HARNESS_ROOT="${runtime_root}"
  log "Using stable runtime root: ${HARNESS_ROOT}"
}

check_cmd() {
  local name="$1"
  command -v "$name" >/dev/null 2>&1
}

ensure_ripgrep() {
  if check_cmd rg; then
    return 0
  fi

  warn "ripgrep (rg) is missing"
  if check_cmd brew; then
    log "Installing ripgrep via Homebrew..."
    if brew install ripgrep; then
      hash -r
      if check_cmd rg; then
        log "ripgrep installed: $(command -v rg)"
        return 0
      fi

      local rg_prefix
      rg_prefix="$(brew --prefix ripgrep 2>/dev/null || true)"
      if [ -n "$rg_prefix" ] && [ -d "$rg_prefix/bin" ]; then
        fail "ripgrep installed but rg is not on PATH. Add ${rg_prefix}/bin to PATH and retry."
      fi
      fail "ripgrep installation finished but rg command is still unavailable."
    fi
    fail "Failed to install ripgrep automatically. Install it manually: brew install ripgrep"
  fi

  fail "Required command not found: rg (ripgrep). Install it first (macOS: brew install ripgrep)."
}

get_cursor_hooks_command() {
  printf '%s' "bash ${HOME}/.cursor/hooks/memory-cursor-event.sh"
}

ensure_dependencies() {
  require_cmd bun
  require_cmd curl
  require_cmd jq
  require_cmd node
  require_cmd npm
  ensure_ripgrep
}

ensure_version_dependencies() {
  require_cmd curl
  require_cmd jq
  require_cmd python3
}

is_repo_checkout() {
  [ -d "${SOURCE_ROOT}/.git" ]
}

is_npx_runtime_source() {
  case "$SOURCE_ROOT" in
    */.npm/_npx/*)
      return 0
      ;;
  esac
  return 1
}

read_current_harness_mem_version() {
  local pkg_json="${HARNESS_ROOT}/package.json"
  if [ ! -f "$pkg_json" ]; then
    printf ''
    return
  fi
  jq -r '.version // ""' "$pkg_json" 2>/dev/null || printf ''
}

write_auto_update_state() {
  local checked_epoch="$1"
  local installed="$2"
  local latest="$3"
  local status="$4"

  mkdir -p "$(dirname "$AUTO_UPDATE_STATE_PATH")"
  jq -nc \
    --arg checked_at_epoch "$checked_epoch" \
    --arg checked_at "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
    --arg installed "$installed" \
    --arg latest "$latest" \
    --arg status "$status" \
    '{
      last_checked_at_epoch: ($checked_at_epoch | tonumber),
      last_checked_at: $checked_at,
      installed_version: ($installed | select(. != "") // null),
      latest_version: ($latest | select(. != "") // null),
      status: $status
    }' > "$AUTO_UPDATE_STATE_PATH"
}

should_attempt_auto_update() {
  local command="$1"

  case "$command" in
    help|-h|--help|uninstall|versions)
      return 1
      ;;
  esac

  if [ "${HARNESS_MEM_SKIP_AUTO_UPDATE:-0}" = "1" ]; then
    return 1
  fi
  if is_repo_checkout; then
    return 1
  fi
  if is_npx_runtime_source; then
    return 1
  fi
  if [ "$(read_auto_update_enabled)" -ne 1 ]; then
    return 1
  fi
  if ! check_cmd npm; then
    return 1
  fi

  local interval="$AUTO_UPDATE_CHECK_INTERVAL_SEC"
  if ! [[ "$interval" =~ ^[0-9]+$ ]] || [ "$interval" -lt 60 ]; then
    interval=86400
  fi

  local now last_checked elapsed
  now="$(date +%s)"
  last_checked="$(jq -r '.last_checked_at_epoch // 0' "$AUTO_UPDATE_STATE_PATH" 2>/dev/null || echo "0")"
  if ! [[ "$last_checked" =~ ^[0-9]+$ ]]; then
    last_checked=0
  fi
  elapsed=$((now - last_checked))
  if [ "$elapsed" -lt "$interval" ]; then
    return 1
  fi
  return 0
}

maybe_auto_update() {
  local command="$1"
  if ! should_attempt_auto_update "$command"; then
    return 0
  fi

  local now current_version latest_version
  now="$(date +%s)"
  current_version="$(read_current_harness_mem_version)"
  latest_version="$(npm view "$AUTO_UPDATE_PACKAGE" version 2>/dev/null | tr -d '\r' | head -n 1 || true)"

  if [ -z "$latest_version" ]; then
    warn "Auto-update check failed: unable to resolve latest version for ${AUTO_UPDATE_PACKAGE}"
    write_auto_update_state "$now" "$current_version" "" "check_failed"
    return 0
  fi

  if [ -n "$current_version" ] && [ "$current_version" = "$latest_version" ]; then
    write_auto_update_state "$now" "$current_version" "$latest_version" "up_to_date"
    return 0
  fi

  log "Auto-update: installing ${AUTO_UPDATE_PACKAGE}@${AUTO_UPDATE_CHANNEL} (current=${current_version:-unknown}, latest=${latest_version})"
  if npm install -g "${AUTO_UPDATE_PACKAGE}@${AUTO_UPDATE_CHANNEL}" >/dev/null 2>&1; then
    log "Auto-update completed. Updated version will be used on the next command."
    write_auto_update_state "$now" "$current_version" "$latest_version" "updated"
  else
    warn "Auto-update failed. Run manually: npm install -g ${AUTO_UPDATE_PACKAGE}@${AUTO_UPDATE_CHANNEL}"
    write_auto_update_state "$now" "$current_version" "$latest_version" "update_failed"
  fi
}

first_line() {
  local output
  output="$("$@" 2>/dev/null | head -n 1 || true)"
  output="$(printf '%s' "$output" | tr -d '\r')"
  printf '%s' "$output"
}

detect_cli_version() {
  local cmd="$1"
  shift || true
  if ! check_cmd "$cmd"; then
    printf ''
    return
  fi
  first_line "$cmd" "$@"
}

detect_cursor_local_version() {
  local value
  value="$(detect_cli_version cursor --version)"
  if [ -n "$value" ]; then
    printf '%s' "$value"
    return
  fi

  local plist
  for plist in \
    "/Applications/Cursor.app/Contents/Info.plist" \
    "$HOME/Applications/Cursor.app/Contents/Info.plist"; do
    if [ -f "$plist" ]; then
      value="$(/usr/libexec/PlistBuddy -c 'Print :CFBundleShortVersionString' "$plist" 2>/dev/null || true)"
      if [ -n "$value" ]; then
        printf '%s' "$value"
        return
      fi
    fi
  done
  printf ''
}

detect_antigravity_local_version() {
  local value
  value="$(detect_cli_version antigravity --version)"
  if [ -n "$value" ]; then
    printf '%s' "$value"
    return
  fi

  local plist
  for plist in \
    "/Applications/Antigravity.app/Contents/Info.plist" \
    "$HOME/Applications/Antigravity.app/Contents/Info.plist"; do
    if [ -f "$plist" ]; then
      value="$(/usr/libexec/PlistBuddy -c 'Print :CFBundleShortVersionString' "$plist" 2>/dev/null || true)"
      if [ -n "$value" ]; then
        printf '%s' "$value"
        return
      fi
    fi
  done
  printf ''
}

normalize_version_hint() {
  local value="$1"
  local extracted
  extracted="$(printf '%s' "$value" | sed -nE 's/.*(rust-v|v)?([0-9]+\.[0-9]+\.[0-9]+([-.][A-Za-z0-9.]+)?).*/\2/p' | head -n 1)"
  if [ -z "$extracted" ]; then
    printf '%s' "$value" | tr '[:upper:]' '[:lower:]' | xargs
    return
  fi
  printf '%s' "$extracted" | tr '[:upper:]' '[:lower:]'
}

version_status_hint() {
  local installed="$1"
  local latest="$2"
  if [ -z "$installed" ] || [ -z "$latest" ]; then
    printf 'unknown'
    return
  fi
  local ni nl
  ni="$(normalize_version_hint "$installed")"
  nl="$(normalize_version_hint "$latest")"
  if [ "$ni" = "$nl" ]; then
    printf 'up_to_date'
    return
  fi
  if [[ "$ni" == *"$nl"* ]] || [[ "$nl" == *"$ni"* ]]; then
    printf 'up_to_date'
    return
  fi
  printf 'needs_review'
}

detect_antigravity_hooks_signal() {
  local releases_json="$1"
  local hooks_key_present="false"
  local first_hooks_key_version=""
  local signal_version=""
  local signal_excerpt=""
  local signal_type=""
  local detected="false"

  hooks_key_present="$(jq -r '
    def items:
      if type == "array" then .
      elif type == "object" and ((.versions // null) | type == "array") then .versions
      else [] end;
    [items[] | has("hooks")] | any
  ' "$releases_json" 2>/dev/null || printf 'false')"
  [ "$hooks_key_present" = "true" ] || hooks_key_present="false"

  first_hooks_key_version="$(jq -r '
    def items:
      if type == "array" then .
      elif type == "object" and ((.versions // null) | type == "array") then .versions
      else [] end;
    [items[] | select(has("hooks")) | (.version // .tag_name // .name // empty | tostring)] | .[0] // empty
  ' "$releases_json" 2>/dev/null || true)"

  if [ "$hooks_key_present" = "true" ]; then
    detected="true"
    signal_type="hooks_key"
    signal_version="$first_hooks_key_version"
  fi

  while IFS=$'\t' read -r parsed_version parsed_text; do
    [ -n "$parsed_text" ] || continue
    if printf '%s' "$parsed_text" \
      | grep -Eiq '(^|[^a-z])hooks?([^a-z]|$)|tool[._ -]?definition|chat[._ -]?message|session[._ -]?(idle|compacted)|フック'; then
      signal_version="$parsed_version"
      signal_excerpt="$parsed_text"
      signal_type="keyword"
      detected="true"
      break
    fi
  done < <(jq -r '
    def stringify:
      if . == null then ""
      elif type == "string" then .
      else tostring end;
    def items:
      if type == "array" then .
      elif type == "object" and ((.versions // null) | type == "array") then .versions
      else [] end;
    items[]
    | [
        ((.version // .tag_name // .name // "") | tostring),
        (
          [
            (.name // ""),
            (.title // ""),
            (.notes // ""),
            (.releaseNotes // ""),
            (.changelog // ""),
            (.body // ""),
            (.description // ""),
            (.summary // ""),
            (.features | stringify),
            (.changes | stringify),
            (.highlights | stringify),
            (.hooks | stringify)
          ]
          | map(select(length > 0))
          | join(" ")
        )
      ]
    | @tsv
  ' "$releases_json" 2>/dev/null || true)

  signal_excerpt="$(printf '%s' "$signal_excerpt" | sed -E 's/[[:space:]]+/ /g' | cut -c1-160)"

  jq -nc \
    --argjson detected "$detected" \
    --arg signal_version "$signal_version" \
    --arg signal_type "$signal_type" \
    --arg signal_excerpt "$signal_excerpt" \
    '{
      detected: $detected,
      signal_version: ($signal_version | select(. != "") // null),
      signal_type: ($signal_type | select(. != "") // null),
      signal_excerpt: ($signal_excerpt | select(. != "") // null)
    }'
}

versions_impl() {
  ensure_version_dependencies

  mkdir -p "$VERSIONS_DIR"
  local tmp_dir
  tmp_dir="$(mktemp -d)"
  trap 'rm -rf "${tmp_dir:-}"' RETURN

  fetch "https://raw.githubusercontent.com/anthropics/claude-code/main/CHANGELOG.md" \
    "$tmp_dir/claude-code-CHANGELOG.md" &
  fetch "https://api.github.com/repos/openai/codex/releases?per_page=50" \
    "$tmp_dir/codex-releases.json" &
  fetch "https://api.github.com/repos/anomalyco/opencode/releases?per_page=50" \
    "$tmp_dir/opencode-releases.json" &
  fetch "https://cursor.com/changelog" \
    "$tmp_dir/cursor-changelog.html" &
  fetch "https://antigravity-auto-updater-974169037036.us-central1.run.app/releases" \
    "$tmp_dir/antigravity-releases-api.json" &
  wait

  local prev_antigravity_hooks
  prev_antigravity_hooks="$(jq -r '.upstream.antigravity.hooks_detected // false' "$VERSIONS_SNAPSHOT_PATH" 2>/dev/null || printf 'false')"
  [ "$prev_antigravity_hooks" = "true" ] || prev_antigravity_hooks="false"

  local claude_latest codex_latest_stable codex_latest_any opencode_latest antigravity_latest
  local cursor_latest_date cursor_latest_title

  claude_latest="$(awk '/^## [0-9]+\.[0-9]+\.[0-9]+$/ {print $2; exit}' "$tmp_dir/claude-code-CHANGELOG.md" || true)"
  codex_latest_stable="$(jq -r 'map(select((.draft|not) and (.prerelease|not))) | sort_by(.published_at) | reverse | .[0].tag_name // empty' "$tmp_dir/codex-releases.json")"
  codex_latest_any="$(jq -r 'map(select(.draft|not)) | sort_by(.published_at) | reverse | .[0].tag_name // empty' "$tmp_dir/codex-releases.json")"
  opencode_latest="$(jq -r 'map(select((.draft|not) and (.prerelease|not))) | sort_by(.published_at) | reverse | .[0].tag_name // empty' "$tmp_dir/opencode-releases.json")"
  antigravity_latest="$(jq -r '.[0].version // empty' "$tmp_dir/antigravity-releases-api.json")"

  local cursor_parsed
  cursor_parsed="$(python3 - "$tmp_dir/cursor-changelog.html" <<'PY'
import re
import sys
from pathlib import Path
text = Path(sys.argv[1]).read_text(encoding="utf-8", errors="ignore")
m = re.search(r'href="(/changelog/[^"]+)"><time dateTime="([^"]+)"[^>]*>[^<]*</time>.*?<h1[^>]*>\s*<a[^>]*>\s*([^<]+)', text, flags=re.DOTALL|re.IGNORECASE)
if not m:
    print("\t")
else:
    print(f"{m.group(2)}\t{m.group(3).strip()}")
PY
)"
  cursor_latest_date="$(printf '%s' "$cursor_parsed" | awk -F'\t' '{print $1}')"
  cursor_latest_title="$(printf '%s' "$cursor_parsed" | awk -F'\t' '{print $2}')"

  local antigravity_hooks_json antigravity_hooks_detected antigravity_hooks_signal_version
  local antigravity_hooks_signal_type antigravity_hooks_signal_excerpt antigravity_hooks_introduced
  antigravity_hooks_json="$(detect_antigravity_hooks_signal "$tmp_dir/antigravity-releases-api.json")"
  antigravity_hooks_detected="$(printf '%s' "$antigravity_hooks_json" | jq -r '.detected')"
  antigravity_hooks_signal_version="$(printf '%s' "$antigravity_hooks_json" | jq -r '.signal_version // empty')"
  antigravity_hooks_signal_type="$(printf '%s' "$antigravity_hooks_json" | jq -r '.signal_type // empty')"
  antigravity_hooks_signal_excerpt="$(printf '%s' "$antigravity_hooks_json" | jq -r '.signal_excerpt // empty')"
  antigravity_hooks_introduced="false"
  if [ "$antigravity_hooks_detected" = "true" ] && [ "$prev_antigravity_hooks" != "true" ]; then
    antigravity_hooks_introduced="true"
  fi

  local codex_local claude_local opencode_local cursor_local antigravity_local
  codex_local="$(detect_cli_version codex --version)"
  claude_local="$(detect_cli_version claude --version)"
  opencode_local="$(detect_cli_version opencode --version)"
  cursor_local="$(detect_cursor_local_version)"
  antigravity_local="$(detect_antigravity_local_version)"

  local codex_status claude_status opencode_status antigravity_status cursor_status
  codex_status="$(version_status_hint "$codex_local" "$codex_latest_stable")"
  claude_status="$(version_status_hint "$claude_local" "$claude_latest")"
  opencode_status="$(version_status_hint "$opencode_local" "$opencode_latest")"
  antigravity_status="$(version_status_hint "$antigravity_local" "$antigravity_latest")"
  cursor_status="unknown"

  local snapshot
  snapshot="$(jq -nc \
    --arg generated_at "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
    --arg codex_local "$codex_local" \
    --arg claude_local "$claude_local" \
    --arg opencode_local "$opencode_local" \
    --arg cursor_local "$cursor_local" \
    --arg antigravity_local "$antigravity_local" \
    --arg claude_latest "$claude_latest" \
    --arg codex_latest_stable "$codex_latest_stable" \
    --arg codex_latest_any "$codex_latest_any" \
    --arg opencode_latest "$opencode_latest" \
    --arg cursor_latest_date "$cursor_latest_date" \
    --arg cursor_latest_title "$cursor_latest_title" \
    --arg antigravity_latest "$antigravity_latest" \
    --arg antigravity_hooks_signal_version "$antigravity_hooks_signal_version" \
    --arg antigravity_hooks_signal_type "$antigravity_hooks_signal_type" \
    --arg antigravity_hooks_signal_excerpt "$antigravity_hooks_signal_excerpt" \
    --arg codex_status "$codex_status" \
    --arg claude_status "$claude_status" \
    --arg opencode_status "$opencode_status" \
    --arg cursor_status "$cursor_status" \
    --arg antigravity_status "$antigravity_status" \
    --argjson antigravity_hooks_detected "$antigravity_hooks_detected" \
    --argjson antigravity_hooks_introduced "$antigravity_hooks_introduced" \
    '{
      generated_at: $generated_at,
      local: {
        codex: {installed: ($codex_local | select(. != "") // null)},
        claude_code: {installed: ($claude_local | select(. != "") // null)},
        opencode: {installed: ($opencode_local | select(. != "") // null)},
        cursor: {installed: ($cursor_local | select(. != "") // null)},
        antigravity: {installed: ($antigravity_local | select(. != "") // null)}
      },
      upstream: {
        claude_code: {
          latest_stable: ($claude_latest | select(. != "") // null),
          source: "https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md"
        },
        codex: {
          latest_stable: ($codex_latest_stable | select(. != "") // null),
          latest_any: ($codex_latest_any | select(. != "") // null),
          source: "https://github.com/openai/codex/releases"
        },
        opencode: {
          latest_stable: ($opencode_latest | select(. != "") // null),
          source: "https://github.com/anomalyco/opencode/releases"
        },
        cursor: {
          latest_entry_date: ($cursor_latest_date | select(. != "") // null),
          latest_entry_title: ($cursor_latest_title | select(. != "") // null),
          source: "https://cursor.com/changelog"
        },
        antigravity: {
          latest_stable: ($antigravity_latest | select(. != "") // null),
          source: "https://antigravity.google/releases",
          hooks_detected: $antigravity_hooks_detected,
          hooks_signal_version: ($antigravity_hooks_signal_version | select(. != "") // null),
          hooks_signal_type: ($antigravity_hooks_signal_type | select(. != "") // null),
          hooks_signal_excerpt: ($antigravity_hooks_signal_excerpt | select(. != "") // null)
        }
      },
      status: {
        codex: $codex_status,
        claude_code: $claude_status,
        opencode: $opencode_status,
        cursor: $cursor_status,
        antigravity: $antigravity_status
      },
      alerts: {
        antigravity_hooks_introduced: $antigravity_hooks_introduced
      }
    }')"

  printf '%s\n' "$snapshot" >"$VERSIONS_SNAPSHOT_PATH"
  printf '%s\n' "$snapshot" | jq -c . >>"$VERSIONS_HISTORY_PATH"

  log "Version snapshot saved: ${VERSIONS_SNAPSHOT_PATH}"
  log "Version history appended: ${VERSIONS_HISTORY_PATH}"
  if [ "$antigravity_hooks_introduced" = "true" ]; then
    warn "Antigravity hooks signal detected upstream (version: ${antigravity_hooks_signal_version:-unknown}). Review hook wiring requirements."
  fi

  printf '%s\n' "$snapshot" \
    | jq -r '
      "Tool versions:",
      "  codex        local=\(.local.codex.installed // "n/a") upstream=\(.upstream.codex.latest_stable // "n/a") status=\(.status.codex)",
      "  claude_code  local=\(.local.claude_code.installed // "n/a") upstream=\(.upstream.claude_code.latest_stable // "n/a") status=\(.status.claude_code)",
      "  opencode     local=\(.local.opencode.installed // "n/a") upstream=\(.upstream.opencode.latest_stable // "n/a") status=\(.status.opencode)",
      "  cursor       local=\(.local.cursor.installed // "n/a") upstream_date=\(.upstream.cursor.latest_entry_date // "n/a") status=\(.status.cursor)",
      "  antigravity  local=\(.local.antigravity.installed // "n/a") upstream=\(.upstream.antigravity.latest_stable // "n/a") status=\(.status.antigravity)",
      "  antigravity_hooks detected=\(.upstream.antigravity.hooks_detected) introduced=\(.alerts.antigravity_hooks_introduced) version=\(.upstream.antigravity.hooks_signal_version // "n/a")"
    '

  trap - RETURN
  rm -rf "$tmp_dir"
}

ensure_mcp_runtime() {
  local mcp_dir="${HARNESS_ROOT}/mcp-server"
  local mcp_dist="${mcp_dir}/dist/index.js"
  local mcp_src_entry="${mcp_dir}/src/index.ts"
  local mcp_sdk_local="${mcp_dir}/node_modules/@modelcontextprotocol/sdk/package.json"
  local mcp_sdk_root="${HARNESS_ROOT}/node_modules/@modelcontextprotocol/sdk/package.json"

  if [ ! -f "$mcp_dist" ]; then
    [ -f "$mcp_src_entry" ] || fail "MCP dist entry missing and source unavailable: $mcp_dist"
    log "MCP dist entry missing. Bootstrapping local MCP build."
    (
      cd "$mcp_dir"
      npm install --silent --include=dev
      npm run build --silent
    )
  fi

  [ -f "$mcp_dist" ] || fail "MCP dist build failed: $mcp_dist"

  if [ -f "$mcp_sdk_local" ] || [ -f "$mcp_sdk_root" ]; then
    return
  fi

  log "Installing MCP server dependencies (one-time)"
  (
    cd "$mcp_dir"
    npm install --silent
  )
}

remove_marked_block() {
  local file="$1"
  local begin="$2"
  local end="$3"
  local tmp
  tmp="$(mktemp)"
  awk -v begin="$begin" -v end="$end" '
    index($0, begin) { skip = 1; next }
    index($0, end) { skip = 0; next }
    skip != 1 { print $0 }
  ' "$file" >"$tmp"
  mv "$tmp" "$file"
}

setup_codex_wiring() {
  local codex_dir="${HOME}/.codex"
  local cfg="${codex_dir}/config.toml"
  local rules_src="${HARNESS_ROOT}/codex/.codex/rules/harness.rules"
  local rules_dst="${codex_dir}/rules/harness.rules"
  local notify_value="bash ${HARNESS_ROOT}/scripts/hook-handlers/memory-codex-notify.sh"

  mkdir -p "$codex_dir"

  if [ ! -f "$cfg" ]; then
    cat >"$cfg" <<EOF
# Codex Team Config (generated by harness-mem)

$BEGIN_CODEX_NOTIFY
notify = "${notify_value}"
$END_CODEX_NOTIFY

$BEGIN_CODEX_MCP
[mcp_servers.harness]
command = "node"
args = ["${HARNESS_ROOT}/mcp-server/dist/index.js"]
enabled = true

[mcp_servers.harness.env]
HARNESS_MEM_HOST = "${MEM_HOST}"
HARNESS_MEM_PORT = "${MEM_PORT}"
HARNESS_MEM_DB_PATH = "${DB_PATH}"
$END_CODEX_MCP
EOF
    log "Created Codex config: $cfg"
  else
    if ! rg -q 'memory-codex-notify\.sh' "$cfg"; then
      if rg -q '^\s*notify\s*=' "$cfg"; then
        warn "Codex config already has notify=. Add memory notify manually: $cfg"
      else
        cat >>"$cfg" <<EOF

$BEGIN_CODEX_NOTIFY
notify = "${notify_value}"
$END_CODEX_NOTIFY
EOF
        log "Added Codex notify wiring: $cfg"
      fi
    fi

    if rg -q 'notify[[:space:]]*=[[:space:]]*\[[[:space:]]*"bash"[[:space:]]*,[[:space:]]*".*memory-codex-notify\.sh"[[:space:]]*\]' "$cfg"; then
      local tmp
      tmp="$(mktemp)"
      sed -E 's|notify[[:space:]]*=[[:space:]]*\[[[:space:]]*"bash"[[:space:]]*,[[:space:]]*"([^"]*memory-codex-notify\.sh)"[[:space:]]*\]|notify = "bash \1"|' "$cfg" >"$tmp"
      mv "$tmp" "$cfg"
      log "Normalized Codex notify wiring format: $cfg"
    fi

    if ! rg -q '^\[mcp_servers\.harness\]' "$cfg"; then
      cat >>"$cfg" <<EOF

$BEGIN_CODEX_MCP
[mcp_servers.harness]
command = "node"
args = ["${HARNESS_ROOT}/mcp-server/dist/index.js"]
enabled = true

[mcp_servers.harness.env]
HARNESS_MEM_HOST = "${MEM_HOST}"
HARNESS_MEM_PORT = "${MEM_PORT}"
HARNESS_MEM_DB_PATH = "${DB_PATH}"
$END_CODEX_MCP
EOF
      log "Added Codex MCP wiring: $cfg"
    fi
  fi

  if [ -f "$rules_src" ] && [ ! -f "$rules_dst" ]; then
    mkdir -p "$(dirname "$rules_dst")"
    cp "$rules_src" "$rules_dst"
    log "Copied memory-aware Codex rules: $rules_dst"
  fi
}

check_codex_wiring() {
  local cfg="${HOME}/.codex/config.toml"
  local failed=0

  if [ ! -f "$cfg" ]; then
    warn "Missing Codex config: $cfg"
    return 1
  fi

  if rg -q 'memory-codex-notify\.sh' "$cfg"; then
    log "Codex notify wiring: OK"
  else
    warn "Codex notify wiring is missing in: $cfg"
    failed=1
  fi

  if rg -q '^\[mcp_servers\.harness\]' "$cfg"; then
    log "Codex MCP wiring: OK"
  else
    warn "Codex MCP wiring is missing in: $cfg"
    failed=1
  fi

  local prepare_hook
  prepare_hook="$(git -C "$TARGET_DIR" rev-parse --git-path hooks/prepare-commit-msg 2>/dev/null || true)"
  if [ -n "$prepare_hook" ] && [ -f "$prepare_hook" ]; then
    if rg -qi 'codex|command_attribution|prepare-commit-msg' "$prepare_hook"; then
      log "Codex git hook coexistence: prepare-commit-msg detected ($prepare_hook)"
    else
      log "Git prepare-commit-msg hook detected (left untouched by harness-mem): $prepare_hook"
    fi
  else
    log "Git prepare-commit-msg hook: not found in current repository (coexistence check skipped)"
  fi

  return "$failed"
}

get_claude_config_targets() {
  local primary="${HOME}/.claude.json"
  local secondary="${HOME}/.claude/settings.json"
  local emitted=0

  if [ -f "$primary" ]; then
    printf '%s\n' "$primary"
    emitted=1
  fi

  if [ -f "$secondary" ]; then
    if jq -e 'has("mcpServers")' "$secondary" >/dev/null 2>&1; then
      printf '%s\n' "$secondary"
      emitted=1
    fi
  fi

  if [ "$emitted" -eq 0 ]; then
    printf '%s\n' "$primary"
  fi
}

upsert_claude_json() {
  local file="$1"
  local mcp_entry="${HARNESS_ROOT}/mcp-server/dist/index.js"
  local tmp

  mkdir -p "$(dirname "$file")"

  if [ ! -f "$file" ]; then
    cat >"$file" <<'EOF'
{
  "mcpServers": {}
}
EOF
    log "Created Claude config: $file"
  fi

  tmp="$(mktemp)"
  if jq \
    --arg mcp_entry "$mcp_entry" \
    --arg host "$MEM_HOST" \
    --arg port "$MEM_PORT" \
    --arg db_path "$DB_PATH" \
    '
      .mcpServers = (.mcpServers // {})
      | .mcpServers.harness = (.mcpServers.harness // {})
      | .mcpServers.harness.command = "node"
      | .mcpServers.harness.args = [$mcp_entry]
      | .mcpServers.harness.enabled = true
      | .mcpServers.harness.env = ((.mcpServers.harness.env // {}) + {
          "HARNESS_MEM_HOST": $host,
          "HARNESS_MEM_PORT": $port,
          "HARNESS_MEM_DB_PATH": $db_path
        })
    ' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Updated Claude MCP wiring: $file"
    return 0
  fi

  rm -f "$tmp"
  warn "Could not parse Claude config JSON: $file"
  return 1
}

setup_claude_wiring() {
  local failed=0
  local any_target=0
  while IFS= read -r cfg; do
    [ -n "$cfg" ] || continue
    any_target=1
    upsert_claude_json "$cfg" || failed=1
  done < <(get_claude_config_targets)

  if [ "$any_target" -eq 0 ] || [ "$failed" -ne 0 ]; then
    fail "Failed to set up Claude MCP wiring"
  fi
}

upsert_cursor_hooks_json() {
  local file="$1"
  local hook_command="$2"
  local tmp
  local template="${HARNESS_ROOT}/.cursor/hooks.json.example"

  mkdir -p "$(dirname "$file")"

  if [ ! -f "$file" ]; then
    if [ -f "$template" ]; then
      cp "$template" "$file"
    else
      cat >"$file" <<EOF
{
  "version": 1,
  "hooks": {
    "beforeSubmitPrompt": [
      { "command": "${hook_command}" }
    ],
    "afterMCPExecution": [
      { "command": "${hook_command}" }
    ],
    "afterShellExecution": [
      { "command": "${hook_command}" }
    ],
    "afterFileEdit": [
      { "command": "${hook_command}" }
    ],
    "stop": [
      { "command": "${hook_command}" }
    ]
  }
}
EOF
    fi
    log "Created Cursor hooks config: $file"
  fi

  tmp="$(mktemp)"
  if jq --arg cmd "$hook_command" '
    def strip_memory_hook:
      map(
        if type == "object" then
          select(((.command // "") | contains("memory-cursor-event.sh")) | not)
        else
          .
        end
      );
    def has_exact_cmd($cmd):
      any(type == "object" and ((.command // "") == $cmd));
    def ensure_cmd($cmd):
      if has_exact_cmd($cmd) then . else . + [{command: $cmd}] end;

    .version = (.version // 1)
    | .hooks = (.hooks // {})
    | .hooks.beforeSubmitPrompt = ((.hooks.beforeSubmitPrompt // []) | strip_memory_hook | ensure_cmd($cmd))
    | .hooks.afterMCPExecution = ((.hooks.afterMCPExecution // []) | strip_memory_hook | ensure_cmd($cmd))
    | .hooks.afterShellExecution = ((.hooks.afterShellExecution // []) | strip_memory_hook | ensure_cmd($cmd))
    | .hooks.afterFileEdit = ((.hooks.afterFileEdit // []) | strip_memory_hook | ensure_cmd($cmd))
    | .hooks.stop = ((.hooks.stop // []) | strip_memory_hook | ensure_cmd($cmd))
  ' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Updated Cursor hooks config: $file"
  else
    rm -f "$tmp"
    warn "Could not parse Cursor hooks JSON: $file"
  fi
}

setup_cursor_hook_script() {
  local script_path="${HOME}/.cursor/hooks/memory-cursor-event.sh"
  local template="${HARNESS_ROOT}/.cursor/hooks/memory-cursor-event.sh"

  mkdir -p "$(dirname "$script_path")"

  if [ -f "$template" ]; then
    cp "$template" "$script_path"
  else
    cat >"$script_path" <<'EOF'
#!/bin/bash
set +e
exit 0
EOF
  fi

  local escaped_root
  escaped_root="$(printf '%s' "$HARNESS_ROOT" | sed 's/[\/&]/\\&/g')"
  local tmp
  tmp="$(mktemp)"
  sed "s/__HARNESS_ROOT__/${escaped_root}/g" "$script_path" >"$tmp"
  mv "$tmp" "$script_path"
  chmod +x "$script_path"
}

setup_cursor_wiring() {
  local hooks_json="${HOME}/.cursor/hooks.json"
  local mcp_json="${HOME}/.cursor/mcp.json"
  local hook_command
  hook_command="$(get_cursor_hooks_command)"
  setup_cursor_hook_script
  upsert_cursor_hooks_json "$hooks_json" "$hook_command"
  upsert_cursor_mcp_json "$mcp_json"
}

upsert_cursor_mcp_json() {
  local file="$1"
  local mcp_entry="${HARNESS_ROOT}/mcp-server/dist/index.js"
  local tmp

  mkdir -p "$(dirname "$file")"

  if [ ! -f "$file" ]; then
    cat >"$file" <<'EOF'
{
  "mcpServers": {}
}
EOF
    log "Created Cursor MCP config: $file"
  fi

  tmp="$(mktemp)"
  if jq \
    --arg mcp_entry "$mcp_entry" \
    --arg host "$MEM_HOST" \
    --arg port "$MEM_PORT" \
    --arg db_path "$DB_PATH" \
    '
      .mcpServers = (.mcpServers // {})
      | .mcpServers.harness = (.mcpServers.harness // {})
      | .mcpServers.harness.type = (.mcpServers.harness.type // "stdio")
      | .mcpServers.harness.command = "node"
      | .mcpServers.harness.args = [$mcp_entry]
      | .mcpServers.harness.env = ((.mcpServers.harness.env // {}) + {
          "HARNESS_MEM_HOST": $host,
          "HARNESS_MEM_PORT": $port,
          "HARNESS_MEM_DB_PATH": $db_path
        })
    ' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Updated Cursor MCP wiring: $file"
    return 0
  fi

  rm -f "$tmp"
  warn "Could not parse Cursor MCP JSON: $file"
  return 1
}

check_cursor_wiring() {
  local hooks_json="${HOME}/.cursor/hooks.json"
  local mcp_json="${HOME}/.cursor/mcp.json"
  local hook_script="${HOME}/.cursor/hooks/memory-cursor-event.sh"
  local mcp_entry="${HARNESS_ROOT}/mcp-server/dist/index.js"
  local hook_command
  hook_command="$(get_cursor_hooks_command)"
  local failed=0

  if [ ! -f "$hook_script" ]; then
    warn "Cursor hook script missing: $hook_script"
    failed=1
  else
    log "Cursor hook script: OK"
  fi

  if [ ! -f "$hooks_json" ]; then
    warn "Cursor hooks config missing: $hooks_json"
    failed=1
  else
    if jq -e --arg cmd "$hook_command" '
      (.hooks.beforeSubmitPrompt // [] | any((.command // "") == $cmd or ((.command // "") | contains("memory-cursor-event.sh"))))
      and (.hooks.afterMCPExecution // [] | any((.command // "") == $cmd or ((.command // "") | contains("memory-cursor-event.sh"))))
      and (.hooks.afterShellExecution // [] | any((.command // "") == $cmd or ((.command // "") | contains("memory-cursor-event.sh"))))
      and (.hooks.afterFileEdit // [] | any((.command // "") == $cmd or ((.command // "") | contains("memory-cursor-event.sh"))))
      and (.hooks.stop // [] | any((.command // "") == $cmd or ((.command // "") | contains("memory-cursor-event.sh"))))
    ' "$hooks_json" >/dev/null 2>&1; then
      log "Cursor hooks JSON wiring: OK"
    else
      warn "Cursor hooks wiring is incomplete: $hooks_json"
      failed=1
    fi
  fi

  if [ ! -f "$mcp_json" ]; then
    warn "Cursor MCP config missing: $mcp_json"
    failed=1
  else
    if jq -e --arg mcp_entry "$mcp_entry" '
      .mcpServers.harness != null
      and (
        (
          (.mcpServers.harness.command // "") == "node"
          and ((.mcpServers.harness.args // []) | any(. == $mcp_entry))
        )
        or (
          (.mcpServers.harness.command // "") == "npx"
          and ((.mcpServers.harness.args // []) | any((. | tostring) | contains("harness-mcp-server") or contains("harness-mem")))
        )
      )
    ' "$mcp_json" >/dev/null 2>&1; then
      log "Cursor MCP wiring: OK"
    else
      warn "Cursor MCP wiring is incomplete: $mcp_json"
      failed=1
    fi
  fi

  return "$failed"
}

setup_antigravity_wiring() {
  log "Antigravity ingest uses workspace file scanning (docs/checkpoints + logs/codex-responses)"
}

check_antigravity_wiring() {
  local roots="${HARNESS_MEM_ANTIGRAVITY_ROOTS:-}"
  if [ -z "$roots" ]; then
    log "Antigravity roots are not explicitly configured (auto-discovery mode)"
    return 0
  fi

  local failed=0
  local IFS=','
  for raw in $roots; do
    local root
    root="$(printf '%s' "$raw" | xargs)"
    [ -z "$root" ] && continue
    if [ -d "$root" ]; then
      log "Antigravity root: OK ($root)"
    else
      warn "Antigravity root not found: $root"
      failed=1
    fi
  done
  return "$failed"
}

print_post_setup_next_steps() {
  log "Next step: verify wiring with doctor"
  log "  ./scripts/harness-mem doctor --project ${TARGET_DIR} --platform ${PLATFORM}"

  if is_platform_enabled cursor; then
    local hooks_json="${HOME}/.cursor/hooks.json"
    local mcp_json="${HOME}/.cursor/mcp.json"
    if [ -f "$hooks_json" ]; then
      log "Cursor wiring file: ${hooks_json}"
    else
      warn "Cursor wiring file is missing: ${hooks_json}"
    fi
    if [ -f "$mcp_json" ]; then
      log "Cursor MCP file: ${mcp_json}"
    else
      warn "Cursor MCP file is missing: ${mcp_json}"
    fi
    log "Cursor verification: send one prompt in Cursor, then check feed"
    log "  curl -sS 'http://${MEM_HOST}:${MEM_PORT}/v1/feed?project=$(basename "$TARGET_DIR")&limit=5&include_private=false' | jq '.ok, .meta.count'"
  fi

  if is_platform_enabled antigravity; then
    if [ -z "${HARNESS_MEM_ANTIGRAVITY_ROOTS:-}" ]; then
      log "Antigravity roots: auto-discovery from Antigravity workspaceStorage"
      log "  (optional) export HARNESS_MEM_ANTIGRAVITY_ROOTS=/absolute/path/to/antigravity-workspace"
    else
      log "Antigravity roots: ${HARNESS_MEM_ANTIGRAVITY_ROOTS}"
    fi
  fi
}

upsert_opencode_json() {
  local file="$1"
  local mcp_entry="${HARNESS_ROOT}/mcp-server/dist/index.js"
  local tmp

  mkdir -p "$(dirname "$file")"

  if [ ! -f "$file" ]; then
    cat >"$file" <<EOF
{
  "\$schema": "https://opencode.ai/config.json",
  "mcp": {
    "harness": {
      "type": "local",
      "enabled": true,
      "command": ["node", "${mcp_entry}"],
      "environment": {
        "HARNESS_MEM_HOST": "${MEM_HOST}",
        "HARNESS_MEM_PORT": "${MEM_PORT}",
        "HARNESS_MEM_DB_PATH": "${DB_PATH}"
      }
    }
  }
}
EOF
    log "Created OpenCode config: $file"
    return
  fi

  tmp="$(mktemp)"
  jq \
    --arg mcp_entry "$mcp_entry" \
    --arg host "$MEM_HOST" \
    --arg port "$MEM_PORT" \
    --arg db_path "$DB_PATH" \
    '
      .["$schema"] = (.["$schema"] // "https://opencode.ai/config.json")
      | .mcp = (.mcp // {})
      | .mcp.harness = (.mcp.harness // {})
      | .mcp.harness.type = "local"
      | .mcp.harness.enabled = true
      | .mcp.harness.command = ["node", $mcp_entry]
      | .mcp.harness.environment = ((.mcp.harness.environment // {}) + {
          "HARNESS_MEM_HOST": $host,
          "HARNESS_MEM_PORT": $port,
          "HARNESS_MEM_DB_PATH": $db_path
        })
      | .mcp.harness |= del(.env)
      | del(.plugins)
    ' "$file" >"$tmp"
  mv "$tmp" "$file"
  log "Updated OpenCode config: $file"
}

setup_opencode_wiring() {
  local opencode_dir="${HOME}/.config/opencode"
  local plugin_src="${HARNESS_ROOT}/opencode/plugins/harness-memory/index.ts"
  local plugin_dst="${opencode_dir}/plugins/harness-memory/index.ts"
  local cfg="${opencode_dir}/opencode.json"

  [ -f "$plugin_src" ] || fail "OpenCode plugin template missing: $plugin_src"

  mkdir -p "$(dirname "$plugin_dst")"
  cp "$plugin_src" "$plugin_dst"
  log "Installed OpenCode memory plugin: $plugin_dst"

  upsert_opencode_json "$cfg"
}

check_opencode_wiring() {
  local failed=0
  local cfg="${HOME}/.config/opencode/opencode.json"
  local plugin="${HOME}/.config/opencode/plugins/harness-memory/index.ts"

  if [ ! -f "$plugin" ]; then
    warn "OpenCode memory plugin file missing: $plugin"
    failed=1
  else
    log "OpenCode global plugin: OK"
    if rg -q '"chat.message"|"session.idle"|"session.compacted"' "$plugin"; then
      log "OpenCode hook compatibility baseline: OK (chat.message/session.idle/session.compacted)"
    else
      warn "OpenCode plugin hook compatibility baseline is incomplete: $plugin"
      failed=1
    fi
    if rg -qi 'tool\.definition|shell\.env' "$plugin"; then
      log "OpenCode extended hook surface: detected (tool.definition/shell.env)"
    else
      log "OpenCode extended hook surface: not configured (baseline mode)"
    fi
  fi

  if [ ! -f "$cfg" ]; then
    warn "OpenCode global config missing: $cfg"
    failed=1
  else
    if jq -e '.mcp.harness.enabled == true' "$cfg" >/dev/null 2>&1; then
      log "OpenCode MCP wiring: OK"
    else
      warn "OpenCode config exists but harness MCP wiring is incomplete"
      failed=1
    fi

    log "OpenCode plugin loading: global plugins directory mode"
  fi

  return "$failed"
}

check_claude_wiring() {
  local failed=0
  local hooks="${HARNESS_ROOT}/hooks/hooks.json"
  local mcp_entry="${HARNESS_ROOT}/mcp-server/dist/index.js"
  local found_mcp=0

  if [ ! -f "$hooks" ]; then
    warn "Claude hooks config missing in harness: $hooks"
    failed=1
  elif rg -q 'memory-session-start|memory-user-prompt|memory-post-tool-use|memory-stop' "$hooks"; then
    log "Claude memory hooks in harness plugin: OK"
  else
    warn "Claude hooks found but memory handlers are missing in: $hooks"
    failed=1
  fi

  while IFS= read -r cfg; do
    [ -n "$cfg" ] || continue
    if [ ! -f "$cfg" ]; then
      warn "Claude config missing: $cfg"
      continue
    fi

    if jq -e --arg mcp_entry "$mcp_entry" '
      .mcpServers.harness != null
      and ((.mcpServers.harness.enabled // true) != false)
      and (
        (
          (.mcpServers.harness.command // "") == "node"
          and ((.mcpServers.harness.args // []) | type == "array")
          and ((.mcpServers.harness.args // []) | any(. == $mcp_entry))
        )
        or (
          (.mcpServers.harness.command // "") == "npx"
          and ((.mcpServers.harness.args // []) | any((. | tostring) | contains("harness-mcp-server") or contains("harness-mem")))
        )
      )
    ' "$cfg" >/dev/null 2>&1; then
      log "Claude MCP wiring: OK ($cfg)"
      found_mcp=1
    fi
  done < <(get_claude_config_targets)

  if [ "$found_mcp" -eq 0 ]; then
    warn "Claude MCP wiring is missing or incomplete (expected mcpServers.harness)"
    failed=1
  fi

  return "$failed"
}

start_daemon() {
  HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
    HARNESS_MEM_HOST="$MEM_HOST" \
    HARNESS_MEM_PORT="$MEM_PORT" \
    HARNESS_MEM_DB_PATH="$DB_PATH" \
    "$HARNESS_ROOT/scripts/harness-memd" start --quiet
}

run_smoke() {
  log "Running isolated smoke test"

  (
    set -euo pipefail
    tmp_home=""
    smoke_port=""
    project_name=""
    marker=""
    health=""
    default_search=""
    private_search=""
    cleanup_done=0

    tmp_home="$(mktemp -d)"
    smoke_port="$((40000 + RANDOM % 2000))"
    project_name="$(basename "$TARGET_DIR")"
    marker="smoke-$(date +%s)-$RANDOM"

    cleanup() {
      if [ "$cleanup_done" -eq 0 ]; then
        HARNESS_MEM_HOME="$tmp_home" \
          HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
          HARNESS_MEM_HOST="127.0.0.1" \
          HARNESS_MEM_PORT="$smoke_port" \
          HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
          "$HARNESS_ROOT/scripts/harness-memd" stop --quiet >/dev/null 2>&1 || true
        rm -rf "$tmp_home"
        cleanup_done=1
      fi
    }

    trap cleanup EXIT

    HARNESS_MEM_HOME="$tmp_home" \
      HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
      HARNESS_MEM_HOST="127.0.0.1" \
      HARNESS_MEM_PORT="$smoke_port" \
      HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
      "$HARNESS_ROOT/scripts/harness-memd" start --quiet

    health="$(
      HARNESS_MEM_HOME="$tmp_home" \
      HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
      HARNESS_MEM_HOST="127.0.0.1" \
      HARNESS_MEM_PORT="$smoke_port" \
      HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
      "$HARNESS_ROOT/scripts/harness-mem-client.sh" health
    )"
    printf '%s' "$health" | jq -e '.ok == true' >/dev/null

    jq -nc \
      --arg project "$project_name" \
      --arg marker "$marker" \
      '{event:{platform:"codex",project:$project,session_id:"smoke-session",event_type:"user_prompt",payload:{content:("public " + $marker)},tags:["smoke"],privacy_tags:[]}}' \
      | HARNESS_MEM_HOME="$tmp_home" \
        HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
        HARNESS_MEM_HOST="127.0.0.1" \
        HARNESS_MEM_PORT="$smoke_port" \
        HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
        "$HARNESS_ROOT/scripts/harness-mem-client.sh" record-event >/dev/null

    jq -nc \
      --arg project "$project_name" \
      --arg marker "$marker" \
      '{event:{platform:"codex",project:$project,session_id:"smoke-session",event_type:"user_prompt",payload:{content:("private " + $marker)},tags:["smoke"],privacy_tags:["private"]}}' \
      | HARNESS_MEM_HOME="$tmp_home" \
        HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
        HARNESS_MEM_HOST="127.0.0.1" \
        HARNESS_MEM_PORT="$smoke_port" \
        HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
        "$HARNESS_ROOT/scripts/harness-mem-client.sh" record-event >/dev/null

    default_search="$(
      jq -nc --arg q "$marker" --arg project "$project_name" '{query:$q,project:$project,limit:10,include_private:false}' \
        | HARNESS_MEM_HOME="$tmp_home" \
          HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
          HARNESS_MEM_HOST="127.0.0.1" \
          HARNESS_MEM_PORT="$smoke_port" \
          HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
          "$HARNESS_ROOT/scripts/harness-mem-client.sh" search
    )"
    printf '%s' "$default_search" | jq -e '.ok == true and (.items | length) >= 1' >/dev/null
    printf '%s' "$default_search" | jq -e '[.items[] | (.privacy_tags // []) | index("private")] | map(select(. != null)) | length == 0' >/dev/null

    private_search="$(
      jq -nc --arg q "$marker" --arg project "$project_name" '{query:$q,project:$project,limit:10,include_private:true}' \
        | HARNESS_MEM_HOME="$tmp_home" \
          HARNESS_MEM_DB_PATH="$tmp_home/harness-mem.db" \
          HARNESS_MEM_HOST="127.0.0.1" \
          HARNESS_MEM_PORT="$smoke_port" \
          HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
          "$HARNESS_ROOT/scripts/harness-mem-client.sh" search
    )"
    printf '%s' "$private_search" | jq -e '[.items[] | (.privacy_tags // []) | index("private")] | map(select(. != null)) | length >= 1' >/dev/null
  )

  log "Smoke test: OK"
}

run_quality_tests() {
  local quality_script="${HARNESS_ROOT}/tests/test-memory-search-quality.sh"
  [ -x "$quality_script" ] || fail "Quality test script missing or not executable: $quality_script"
  log "Running search quality test suite"
  "$quality_script"
}

run_import_request() {
  local payload="$1"
  HARNESS_MEM_HOME="$STATE_DIR" \
    HARNESS_MEM_DB_PATH="$DB_PATH" \
    HARNESS_MEM_HOST="$MEM_HOST" \
    HARNESS_MEM_PORT="$MEM_PORT" \
    HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
    "$HARNESS_ROOT/scripts/harness-mem-client.sh" import-claude-mem "$payload"
}

run_verify_request() {
  local payload="$1"
  HARNESS_MEM_HOME="$STATE_DIR" \
    HARNESS_MEM_DB_PATH="$DB_PATH" \
    HARNESS_MEM_HOST="$MEM_HOST" \
    HARNESS_MEM_PORT="$MEM_PORT" \
    HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
    "$HARNESS_ROOT/scripts/harness-mem-client.sh" verify-import "$payload"
}

import_claude_mem_impl() {
  ensure_dependencies
  [ -n "$IMPORT_SOURCE" ] || fail "import-claude-mem requires --source <sqlite path>"
  [ -f "$IMPORT_SOURCE" ] || fail "source db not found: $IMPORT_SOURCE"

  start_daemon

  local payload
  payload="$(jq -nc \
    --arg source "$IMPORT_SOURCE" \
    --arg project "$IMPORT_PROJECT" \
    --argjson dry_run "$([ "$IMPORT_DRY_RUN" -eq 1 ] && echo true || echo false)" \
    '{
      source_db_path: $source,
      dry_run: $dry_run
    } + (if $project == "" then {} else {project: $project} end)')"

  local response
  response="$(run_import_request "$payload")"
  printf '%s\n' "$response"

  echo "$response" | jq -e '.ok == true' >/dev/null || fail "import request failed"
  local job_id
  job_id="$(echo "$response" | jq -r '.items[0].job_id // empty')"
  [ -n "$job_id" ] || fail "import response did not include job_id"
  log "Import job: $job_id"
}

verify_import_impl() {
  ensure_dependencies
  [ -n "$IMPORT_JOB_ID" ] || fail "verify-import requires --job <job_id>"
  start_daemon

  local payload
  payload="$(jq -nc --arg job_id "$IMPORT_JOB_ID" '{job_id: $job_id}')"
  local response
  response="$(run_verify_request "$payload")"
  printf '%s\n' "$response"

  echo "$response" | jq -e '.ok == true' >/dev/null || fail "verify API call failed"
  echo "$response" | jq -e '.items[0].ok == true' >/dev/null || fail "import verification failed"
  log "Import verification passed: $IMPORT_JOB_ID"
}

disable_claude_mem_json_refs() {
  local file="$1"
  [ -f "$file" ] || return 0
  local tmp backup
  tmp="$(mktemp)"
  backup="${file}.pre-harness-cutover.$(date +%s)"
  cp "$file" "$backup" >/dev/null 2>&1 || true

  if jq '
      def scrub:
        if type == "object" then
          with_entries(.value |= scrub)
          | with_entries(
              select(
                (
                  (.value | tostring | ascii_downcase | contains("claude-mem"))
                  or
                  (.key | ascii_downcase | contains("claude-mem"))
                ) | not
              )
            )
        elif type == "array" then
          map(scrub)
          | map(
              select(
                (. | tostring | ascii_downcase | contains("claude-mem")) | not
              )
            )
        else .
        end;
      scrub
    ' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Removed claude-mem references from $file (backup: $backup)"
  else
    rm -f "$tmp"
    warn "Could not sanitize $file (invalid JSON?)"
  fi
}

stop_claude_mem_runtime() {
  local stopped=0
  if command -v claude-mem >/dev/null 2>&1; then
    claude-mem stop >/dev/null 2>&1 || true
    stopped=1
  fi

  local pids
  pids="$(pgrep -f '(^|[ /])claude-mem([[:space:]]|$)' || true)"
  if [ -n "$pids" ]; then
    echo "$pids" | while read -r pid; do
      [ -n "$pid" ] || continue
      kill -TERM "$pid" >/dev/null 2>&1 || true
    done
    sleep 1
    local remaining
    remaining="$(pgrep -f '(^|[ /])claude-mem([[:space:]]|$)' || true)"
    if [ -n "$remaining" ]; then
      echo "$remaining" | while read -r pid; do
        [ -n "$pid" ] || continue
        kill -KILL "$pid" >/dev/null 2>&1 || true
      done
    fi
    stopped=1
  fi

  local plist
  for plist in "$HOME"/Library/LaunchAgents/*claude*mem*.plist; do
    [ -e "$plist" ] || continue
    launchctl unload "$plist" >/dev/null 2>&1 || true
    mv "$plist" "${plist}.disabled" >/dev/null 2>&1 || true
    stopped=1
  done

  disable_claude_mem_json_refs "$HOME/.claude/hooks.json"
  disable_claude_mem_json_refs "$HOME/.claude/settings.json"

  if [ "$stopped" -eq 1 ]; then
    log "Claude-mem runtime/autostart disabled"
  else
    warn "No running Claude-mem process or launch agent was found"
  fi
}

cutover_claude_mem_impl() {
  ensure_dependencies
  [ -n "$IMPORT_JOB_ID" ] || fail "cutover-claude-mem requires --job <job_id>"
  [ "$STOP_NOW" -eq 1 ] || fail "cutover requires explicit --stop-now"
  start_daemon

  local payload verify_response
  payload="$(jq -nc --arg job_id "$IMPORT_JOB_ID" '{job_id: $job_id}')"
  verify_response="$(run_verify_request "$payload")"
  echo "$verify_response" | jq -e '.ok == true and .items[0].ok == true' >/dev/null \
    || fail "verify failed; cutover aborted"

  stop_claude_mem_runtime
  log "Cutover completed for job: $IMPORT_JOB_ID"
}

migrate_from_claude_mem_impl() {
  local source_db="${HOME}/.claude-mem/claude-mem.db"
  [ -f "$source_db" ] || fail "Claude-mem source DB not found: $source_db"

  ensure_dependencies
  start_daemon

  # Step 1: import
  log "Step 1/3: Importing from Claude-mem..."
  local import_payload import_response job_id
  import_payload="$(jq -nc --arg source "$source_db" '{ source_db_path: $source, dry_run: false }')"
  import_response="$(run_import_request "$import_payload")"
  echo "$import_response" | jq -e '.ok == true' >/dev/null || fail "Import failed"
  job_id="$(echo "$import_response" | jq -r '.items[0].job_id // empty')"
  [ -n "$job_id" ] || fail "Import did not return job_id"
  log "Import started: job=$job_id"

  # Step 2: verify
  log "Step 2/3: Verifying import..."
  local verify_payload verify_response
  verify_payload="$(jq -nc --arg job_id "$job_id" '{job_id: $job_id}')"
  verify_response="$(run_verify_request "$verify_payload")"
  echo "$verify_response" | jq -e '.ok == true and .items[0].ok == true' >/dev/null || fail "Verification failed. Run: harness-mem verify-import --job $job_id"
  log "Verification passed"

  # Step 3: cutover
  log "Step 3/3: Cutting over from Claude-mem..."
  stop_claude_mem_runtime
  log "Migration complete! Claude-mem has been stopped."
  log "Rollback: harness-mem rollback-claude-mem"
}

rollback_claude_mem_impl() {
  log "Rolling back to Claude-mem..."
  # Restart Claude-mem if available
  if command -v claude-mem >/dev/null 2>&1; then
    claude-mem start 2>/dev/null || true
    log "Claude-mem restarted"
  else
    warn "claude-mem command not found. Manual restart required."
  fi
  # Re-enable LaunchAgent if disabled
  local plist
  for plist in "$HOME"/Library/LaunchAgents/*claude*mem*.plist.disabled; do
    [ -e "$plist" ] || continue
    local original="${plist%.disabled}"
    mv "$plist" "$original" 2>/dev/null || true
    launchctl load "$original" 2>/dev/null || true
    log "Re-enabled: $original"
  done
  log "Rollback complete. Verify with: claude-mem status"
}

run_setup_claude_mem_import_if_requested() {
  if [ "$SETUP_IMPORT_CLAUDE_MEM" -ne 1 ]; then
    return
  fi

  local source_db="${HOME}/.claude-mem/claude-mem.db"
  [ -f "$source_db" ] || fail "Claude-mem source DB not found: $source_db"

  start_daemon

  local payload response job_id verify_payload verify_response imported_count
  payload="$(jq -nc \
    --arg source "$source_db" \
    '{
      source_db_path: $source,
      dry_run: false
    }')"

  response="$(run_import_request "$payload")"
  echo "$response" | jq -e '.ok == true' >/dev/null || fail "Claude-mem import request failed during setup"

  job_id="$(echo "$response" | jq -r '.items[0].job_id // empty')"
  [ -n "$job_id" ] || fail "Claude-mem import did not return job_id during setup"
  log "Claude-mem import requested (job=${job_id})"

  verify_payload="$(jq -nc --arg job_id "$job_id" '{job_id: $job_id}')"
  verify_response="$(run_verify_request "$verify_payload")"
  echo "$verify_response" | jq -e '.ok == true and .items[0].ok == true' >/dev/null \
    || fail "Claude-mem import verification failed during setup"
  imported_count="$(echo "$verify_response" | jq -r '.items[0].imported_observations // 0')"
  log "Claude-mem import verified (job=${job_id}, imported_observations=${imported_count})"

  if [ "$SETUP_STOP_CLAUDE_MEM_AFTER_IMPORT" -eq 1 ]; then
    stop_claude_mem_runtime
    log "Claude-mem stop completed after setup import"
  fi
}

doctor_impl() {
  local failed=0
  # JSON出力用チェック結果配列
  local -a doctor_checks=()

  # ヘルパー: チェック結果を記録する
  # 引数: name status fix
  _doctor_record() {
    local name="$1" status="$2" fix="$3"
    doctor_checks+=("$(printf '%s\t%s\t%s' "$name" "$status" "$fix")")
  }

  # Backend mode check
  local current_backend
  current_backend="$(read_backend_mode)"
  _doctor_record "backend_mode" "ok:${current_backend}" ""
  log "Backend mode: ${current_backend}"

  # config.json existence
  if [ -f "$CONFIG_PATH" ]; then
    _doctor_record "config" "ok" ""
  else
    ensure_config
    _doctor_record "config" "ok" ""
    log "Created default config at ${CONFIG_PATH}"
  fi

  # managed backend connectivity (only for managed/hybrid)
  if [ "$current_backend" = "managed" ] || [ "$current_backend" = "hybrid" ]; then
    local managed_ep
    managed_ep="$(read_managed_endpoint)"
    if [ -n "$managed_ep" ]; then
      if curl --silent --show-error --fail --max-time 3 "${managed_ep}/health" >/dev/null 2>&1; then
        _doctor_record "managed_backend" "ok" ""
      else
        _doctor_record "managed_backend" "unreachable" "check managed endpoint: ${managed_ep}"
        failed=1
      fi
    else
      _doctor_record "managed_backend" "not_configured" "set managed.endpoint in ${CONFIG_PATH}"
      failed=1
    fi
  fi

  # 依存コマンドチェック
  if [ "$FIX_MODE" -eq 1 ]; then
    ensure_ripgrep
  fi

  if check_cmd bun; then
    _doctor_record "bun" "ok" ""
  else
    warn "bun is missing"
    _doctor_record "bun" "missing" "brew install bun"
    failed=1
  fi
  if check_cmd curl; then
    _doctor_record "curl" "ok" ""
  else
    warn "curl is missing"
    _doctor_record "curl" "missing" "brew install curl"
    failed=1
  fi
  if check_cmd jq; then
    _doctor_record "jq" "ok" ""
  else
    warn "jq is missing"
    _doctor_record "jq" "missing" "brew install jq"
    failed=1
  fi
  if check_cmd node; then
    _doctor_record "node" "ok" ""
  else
    warn "node is missing"
    _doctor_record "node" "missing" "brew install node"
    failed=1
  fi
  if check_cmd npm; then
    _doctor_record "npm" "ok" ""
  else
    warn "npm is missing"
    _doctor_record "npm" "missing" "brew install node"
    failed=1
  fi
  if check_cmd rg; then
    _doctor_record "rg" "ok" ""
  else
    warn "rg (ripgrep) is missing"
    _doctor_record "rg" "missing" "brew install ripgrep"
    failed=1
  fi

  if check_cmd bun && check_cmd curl && check_cmd npm; then
    ensure_mcp_runtime || failed=1
    local health_url="http://${MEM_HOST}:${MEM_PORT}/health"
    if curl --silent --show-error --fail --max-time 1 "$health_url" >/dev/null 2>&1; then
      log "Daemon endpoint already reachable: ${health_url}"
    else
      HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
        HARNESS_MEM_HOST="$MEM_HOST" \
        HARNESS_MEM_PORT="$MEM_PORT" \
        HARNESS_MEM_DB_PATH="$DB_PATH" \
        "$HARNESS_ROOT/scripts/harness-memd" start --quiet >/dev/null 2>&1 || true
    fi

    HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
      HARNESS_MEM_HOST="$MEM_HOST" \
      HARNESS_MEM_PORT="$MEM_PORT" \
      HARNESS_MEM_DB_PATH="$DB_PATH" \
      "$HARNESS_ROOT/scripts/harness-memd" cleanup-stale --quiet >/dev/null 2>&1 || true

    if HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
      HARNESS_MEM_HOST="$MEM_HOST" \
      HARNESS_MEM_PORT="$MEM_PORT" \
      HARNESS_MEM_DB_PATH="$DB_PATH" \
      "$HARNESS_ROOT/scripts/harness-memd" doctor >/dev/null; then
      log "Daemon doctor: OK"
      _doctor_record "daemon" "ok" ""
    else
      warn "Daemon doctor reported warnings"
      if curl --silent --show-error --fail --max-time 1 "$health_url" >/dev/null 2>&1; then
        warn "Daemon health endpoint is reachable; treating daemon doctor result as warning only"
        _doctor_record "daemon" "ok:reachable_with_warnings" "harness-memd cleanup-stale"
      else
        _doctor_record "daemon" "unhealthy" "harness-memd start"
        failed=1
      fi
    fi
  fi

  if is_platform_enabled codex; then
    if check_codex_wiring; then
      _doctor_record "codex_wiring" "ok" ""
    else
      _doctor_record "codex_wiring" "missing" "harness-mem setup --platform codex"
      failed=1
    fi
  fi
  if is_platform_enabled opencode; then
    if check_opencode_wiring; then
      _doctor_record "opencode_wiring" "ok" ""
    else
      _doctor_record "opencode_wiring" "missing" "harness-mem setup --platform opencode"
      failed=1
    fi
  fi
  if is_platform_enabled claude; then
    if check_claude_wiring; then
      _doctor_record "claude_wiring" "ok" ""
    else
      _doctor_record "claude_wiring" "missing" "harness-mem setup --platform claude"
      failed=1
    fi
  fi
  if is_platform_enabled cursor; then
    if check_cursor_wiring; then
      _doctor_record "cursor_wiring" "ok" ""
    else
      _doctor_record "cursor_wiring" "missing" "harness-mem setup --platform cursor"
      failed=1
    fi
  fi
  if is_platform_enabled antigravity; then
    if check_antigravity_wiring; then
      _doctor_record "antigravity_wiring" "ok" ""
    else
      _doctor_record "antigravity_wiring" "missing" "harness-mem setup --platform antigravity"
      failed=1
    fi
  fi

  # Managed backend connectivity check
  local _doctor_backend_mode
  _doctor_backend_mode="$(read_backend_mode)"
  if [ "$_doctor_backend_mode" = "hybrid" ] || [ "$_doctor_backend_mode" = "managed" ]; then
    local _doctor_managed_ep
    _doctor_managed_ep="$(jq -r '.managed.endpoint // ""' "$CONFIG_PATH" 2>/dev/null || echo "")"
    if [ -z "$_doctor_managed_ep" ]; then
      _doctor_record "managed_endpoint" "missing" "Set managed.endpoint in ${CONFIG_PATH}"
      failed=1
    else
      # Check if daemon reports managed backend status
      local _doctor_shadow_json
      _doctor_shadow_json="$(curl -sf "http://127.0.0.1:${HARNESS_MEM_PORT:-37888}/v1/admin/shadow-metrics" 2>/dev/null)"
      if [ -n "$_doctor_shadow_json" ]; then
        local _doctor_conn_state
        _doctor_conn_state="$(echo "$_doctor_shadow_json" | jq -r '.items[0].connection_state // "unknown"' 2>/dev/null)"
        case "$_doctor_conn_state" in
          connected)
            _doctor_record "managed_endpoint" "ok:${_doctor_backend_mode}" ""
            ;;
          degraded)
            _doctor_record "managed_endpoint" "degraded" "Managed backend connection degraded"
            ;;
          *)
            _doctor_record "managed_endpoint" "ok:configured" "endpoint configured but daemon connection state: ${_doctor_conn_state}"
            ;;
        esac
      else
        _doctor_record "managed_endpoint" "ok:configured" "endpoint configured (daemon not reachable for status check)"
      fi
    fi
  fi

  if [ "$VERSION_CHECK_IN_SETUP" -eq 1 ] && [ "$JSON_OUTPUT" -ne 1 ]; then
    versions_impl || warn "Version snapshot failed during doctor (non-fatal)"
  fi

  # JSON出力モード
  if [ "$JSON_OUTPUT" -eq 1 ]; then
    _doctor_emit_json "$failed" "${doctor_checks[@]}"
    if [ "$failed" -ne 0 ] && [ "$FIX_MODE" -eq 1 ]; then
      warn "Doctor found issues. Running auto-fix."
      setup_impl
    fi
    return 0
  fi

  if [ "$failed" -eq 0 ]; then
    log "Doctor result: healthy"
    return 0
  fi

  if [ "$FIX_MODE" -eq 1 ]; then
    warn "Doctor found issues. Running auto-fix."
    setup_impl
    return
  fi

  # 失敗時のガイド出力
  _doctor_print_next_steps "${doctor_checks[@]}"

  fail "Doctor found issues. Run with --fix to auto-repair."
}

# doctor JSON出力
_doctor_emit_json() {
  local failed="$1"
  shift
  local -a checks=("$@")
  local status_str all_green_str
  local checked_count="${#checks[@]}"
  local failed_count=0
  if [ "$failed" -eq 0 ]; then
    status_str="healthy"
    all_green_str="true"
  else
    status_str="unhealthy"
    all_green_str="false"
  fi

  local checks_json="["
  local first=1
  local entry name status fix
  for entry in "${checks[@]}"; do
    IFS=$'\t' read -r name status fix <<<"$entry"
    if [ "$status" != "ok" ] && [[ "$status" != ok:* ]]; then
      failed_count=$((failed_count + 1))
    fi
    if [ "$first" -eq 0 ]; then
      checks_json+=","
    fi
    checks_json+="$(jq -nc \
      --arg name "$name" \
      --arg status "$status" \
      --arg fix "$fix" \
      '{name: $name, status: $status, fix: (if $fix == "" then null else $fix end)}')"
    first=0
  done
  checks_json+="]"

  local ts
  ts="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

  local current_backend
  current_backend="$(read_backend_mode)"

  jq -n \
    --arg status "$status_str" \
    --argjson all_green "$all_green_str" \
    --argjson failed_count "$failed_count" \
    --argjson checked_count "$checked_count" \
    --arg timestamp "$ts" \
    --arg backend_mode "$current_backend" \
    --argjson checks "$checks_json" \
    '{
      status: $status,
      all_green: $all_green,
      backend_mode: $backend_mode,
      failed_count: $failed_count,
      checked_count: $checked_count,
      timestamp: $timestamp,
      checks: $checks,
      fix_command: "harness-mem doctor --fix"
    }'
}

# doctor失敗時のガイド表示
_doctor_print_next_steps() {
  local -a checks=("$@")
  local entry name status fix
  local has_missing=0
  for entry in "${checks[@]}"; do
    IFS=$'\t' read -r name status fix <<<"$entry"
    if [ "$status" != "ok" ]; then
      has_missing=1
      break
    fi
  done
  [ "$has_missing" -eq 0 ] && return

  if ui_is_en; then
    echo ""
    echo "[harness-mem] Next steps to reach doctor all-green:"
  else
    echo ""
    echo "[harness-mem] doctor 全green到達のための次のアクション:"
  fi

  for entry in "${checks[@]}"; do
    IFS=$'\t' read -r name status fix <<<"$entry"
    [ "$status" = "ok" ] && continue
    if ui_is_en; then
      printf "  [FAIL] %s => %s\n" "$name" "$fix"
    else
      printf "  [FAIL] %s => %s\n" "$name" "$fix"
    fi
  done

  echo ""
  if ui_is_en; then
    echo "  Quick fix: harness-mem doctor --fix"
  else
    echo "  まとめて修復: harness-mem doctor --fix"
  fi
  echo ""
}

setup_impl() {
  # 各ステップの成否を追跡する配列
  # 形式: "step_name\tstatus\tfix_command"
  local -a SETUP_RESULTS=()

  _setup_record() {
    local step="$1" status="$2" fix="$3"
    SETUP_RESULTS+=("$(printf '%s\t%s\t%s' "$step" "$status" "$fix")")
  }

  # Backend mode 設定
  ensure_config
  if [ -n "$BACKEND_MODE" ]; then
    write_backend_mode "$BACKEND_MODE"
    log "Backend mode set to: ${BACKEND_MODE}"
    _setup_record "backend_mode" "ok:${BACKEND_MODE}" ""
  else
    local current_backend
    current_backend="$(read_backend_mode)"
    log "Backend mode: ${current_backend}"
    _setup_record "backend_mode" "ok:${current_backend}" ""
  fi

  local auto_update_enabled
  if [ "$SETUP_AUTO_UPDATE_OPT_IN" -eq 1 ]; then
    write_auto_update_enabled 1
    auto_update_enabled=1
  elif [ "$SETUP_AUTO_UPDATE_OPT_IN" -eq 0 ]; then
    write_auto_update_enabled 0
    auto_update_enabled=0
  else
    auto_update_enabled="$(read_auto_update_enabled)"
  fi

  if [ "$auto_update_enabled" -eq 1 ]; then
    log "Auto-update opt-in: enabled"
    _setup_record "auto_update_opt_in" "ok:enabled" ""
  else
    log "Auto-update opt-in: disabled"
    _setup_record "auto_update_opt_in" "ok:disabled" ""
  fi

  # 依存チェック
  if ensure_dependencies 2>/dev/null; then
    _setup_record "dependencies" "ok" ""
  else
    ensure_dependencies  # エラーメッセージを出す
    _setup_record "dependencies" "failed" "brew install bun curl jq node ripgrep"
    _setup_print_repair_suggestions "${SETUP_RESULTS[@]}"
    return 1
  fi

  if ensure_mcp_runtime 2>/dev/null; then
    _setup_record "mcp_runtime" "ok" ""
  else
    ensure_mcp_runtime
    _setup_record "mcp_runtime" "failed" "cd ${HARNESS_ROOT}/mcp-server && npm install --include=dev && npm run build"
    _setup_print_repair_suggestions "${SETUP_RESULTS[@]}"
    return 1
  fi

  if is_platform_enabled codex; then
    if setup_codex_wiring 2>/dev/null; then
      _setup_record "codex_wiring" "ok" ""
    else
      setup_codex_wiring
      _setup_record "codex_wiring" "failed" "harness-mem setup --platform codex"
    fi
  fi
  if is_platform_enabled opencode; then
    if setup_opencode_wiring 2>/dev/null; then
      _setup_record "opencode_wiring" "ok" ""
    else
      setup_opencode_wiring
      _setup_record "opencode_wiring" "failed" "harness-mem setup --platform opencode"
    fi
  fi
  if is_platform_enabled claude; then
    if setup_claude_wiring 2>/dev/null; then
      _setup_record "claude_wiring" "ok" ""
      check_claude_wiring || true
    else
      setup_claude_wiring
      _setup_record "claude_wiring" "failed" "harness-mem setup --platform claude"
    fi
  fi
  if is_platform_enabled cursor; then
    if setup_cursor_wiring 2>/dev/null; then
      _setup_record "cursor_wiring" "ok" ""
    else
      setup_cursor_wiring
      _setup_record "cursor_wiring" "failed" "harness-mem setup --platform cursor"
    fi
  fi
  if is_platform_enabled antigravity; then
    if setup_antigravity_wiring 2>/dev/null; then
      _setup_record "antigravity_wiring" "ok" ""
    else
      setup_antigravity_wiring
      _setup_record "antigravity_wiring" "failed" "harness-mem setup --platform antigravity"
    fi
  fi

  if [ "$SKIP_START" -eq 0 ]; then
    if start_daemon 2>/dev/null; then
      _setup_record "daemon_start" "ok" ""
      log "Daemon started: http://${MEM_HOST}:${MEM_PORT}"
      local setup_ui_port setup_ui_health
      setup_ui_port="${HARNESS_MEM_UI_PORT:-37901}"
      setup_ui_health="http://${MEM_HOST}:${setup_ui_port}/api/health"
      if curl --silent --show-error --fail --max-time 1 "$setup_ui_health" >/dev/null 2>&1; then
        log "Mem UI started: http://${MEM_HOST}:${setup_ui_port}"
      else
        warn "Mem UI endpoint is not reachable: http://${MEM_HOST}:${setup_ui_port}"
      fi
    else
      start_daemon || true
      _setup_record "daemon_start" "failed" "harness-memd start"
    fi
  fi

  if [ "$SKIP_SMOKE" -eq 0 ]; then
    if run_smoke 2>/dev/null; then
      _setup_record "smoke_test" "ok" ""
    else
      run_smoke || true
      _setup_record "smoke_test" "failed" "harness-mem smoke"
    fi
  fi

  if [ "$SKIP_QUALITY" -eq 0 ]; then
    if run_quality_tests 2>/dev/null; then
      _setup_record "quality_test" "ok" ""
    else
      run_quality_tests || true
      _setup_record "quality_test" "failed" "harness-mem smoke"
    fi
  fi

  run_setup_claude_mem_import_if_requested

  if [ "$VERSION_CHECK_IN_SETUP" -eq 1 ]; then
    versions_impl || warn "Version snapshot failed during setup (non-fatal)"
  fi

  # Doctor JSON 診断を保存（セットアップ時チェック標準化）
  local doctor_artifact="${STATE_DIR}/runtime/doctor-last.json"
  mkdir -p "$(dirname "$doctor_artifact")"
  if HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
     HARNESS_MEM_HOST="$MEM_HOST" \
     HARNESS_MEM_PORT="$MEM_PORT" \
     HARNESS_MEM_DB_PATH="$DB_PATH" \
     "$HARNESS_ROOT/scripts/harness-mem" doctor --json --skip-version-check --platform "$PLATFORM" > "$doctor_artifact" 2>/dev/null; then
    if jq -e '.all_green == true' "$doctor_artifact" >/dev/null 2>&1; then
      _setup_record "doctor_post_check" "ok" ""
      log "Doctor artifact saved: $doctor_artifact"
    else
      _setup_record "doctor_post_check" "failed" "harness-mem doctor --fix"
      local failed_checks
      failed_checks="$(jq -r '.checks[]? | select(.status != "ok" and (.status | startswith("ok:") | not)) | .name' "$doctor_artifact" 2>/dev/null | paste -sd ',' -)"
      if [ -n "$failed_checks" ]; then
        log "Doctor post-check: not all green (checks: ${failed_checks}, artifact: $doctor_artifact)"
      else
        log "Doctor post-check: not all green (artifact: $doctor_artifact)"
      fi
    fi
  else
    _setup_record "doctor_post_check" "failed" "harness-mem doctor --fix"
    warn "Doctor post-check failed (artifact: $doctor_artifact)"
  fi

  # 失敗ステップがあれば修復提案を出す
  local has_failure=0
  local entry step status fix
  for entry in "${SETUP_RESULTS[@]}"; do
    IFS=$'\t' read -r step status fix <<<"$entry"
    if [ "$status" = "failed" ]; then
      has_failure=1
      break
    fi
  done

  if [ "$has_failure" -eq 1 ]; then
    _setup_print_repair_suggestions "${SETUP_RESULTS[@]}"
  else
    log "Setup complete (project=${TARGET_DIR}, platform=${PLATFORM})"
    print_post_setup_next_steps
  fi
}

# setup失敗時の修復提案を表示する
_setup_print_repair_suggestions() {
  local -a results=("$@")
  local entry step status fix
  local has_failure=0
  for entry in "${results[@]}"; do
    IFS=$'\t' read -r step status fix <<<"$entry"
    if [ "$status" = "failed" ]; then
      has_failure=1
      break
    fi
  done
  [ "$has_failure" -eq 0 ] && return

  echo ""
  if ui_is_en; then
    echo "[harness-mem] Setup had failures. Suggested repair steps:"
  else
    echo "[harness-mem] セットアップで失敗がありました。修復手順:"
  fi

  for entry in "${results[@]}"; do
    IFS=$'\t' read -r step status fix <<<"$entry"
    if [ "$status" = "failed" ]; then
      printf "  [FAIL] %-20s => %s\n" "$step" "$fix"
    fi
  done

  echo ""
  if ui_is_en; then
    echo "  Auto-repair: harness-mem doctor --fix --platform ${PLATFORM}"
    echo "  Re-run:      harness-mem setup --platform ${PLATFORM} --skip-smoke --skip-quality"
  else
    echo "  自動修復:    harness-mem doctor --fix --platform ${PLATFORM}"
    echo "  再実行:      harness-mem setup --platform ${PLATFORM} --skip-smoke --skip-quality"
  fi
  echo ""
}

uninstall_codex_wiring() {
  local cfg="${HOME}/.codex/config.toml"
  local tmp
  if [ ! -f "$cfg" ]; then
    return
  fi

  remove_marked_block "$cfg" "$BEGIN_CODEX_NOTIFY" "$END_CODEX_NOTIFY"
  remove_marked_block "$cfg" "$BEGIN_CODEX_MCP" "$END_CODEX_MCP"
  tmp="$(mktemp)"
  awk '
    /^\[mcp_servers\.harness(\.env)?\]/ { skip = 1; next }
    skip == 1 {
      if ($0 ~ /^\[/) {
        skip = 0
        print $0
      }
      next
    }
    /memory-codex-notify\.sh/ { next }
    { print $0 }
  ' "$cfg" >"$tmp"
  mv "$tmp" "$cfg"
  log "Removed Codex marker-managed wiring: $cfg"
}

remove_opencode_wiring_json() {
  local file="$1"
  local tmp
  if [ ! -f "$file" ]; then
    return
  fi
  tmp="$(mktemp)"
  if jq 'del(.plugins["harness-memory"]) | del(.mcp.harness)' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Removed OpenCode memory wiring from: $file"
  else
    rm -f "$tmp"
    warn "Could not parse JSON for cleanup: $file"
  fi
}

remove_claude_wiring_json() {
  local file="$1"
  local tmp
  if [ ! -f "$file" ]; then
    return
  fi
  tmp="$(mktemp)"
  if jq 'if has("mcpServers") then .mcpServers |= del(.harness) else . end' "$file" >"$tmp" 2>/dev/null; then
    mv "$tmp" "$file"
    log "Removed Claude harness MCP wiring from: $file"
  else
    rm -f "$tmp"
    warn "Could not parse JSON for cleanup: $file"
  fi
}

uninstall_claude_wiring() {
  remove_claude_wiring_json "${HOME}/.claude.json"
  remove_claude_wiring_json "${HOME}/.claude/settings.json"
}

uninstall_opencode_wiring() {
  local cfg="${HOME}/.config/opencode/opencode.json"
  local plugin="${HOME}/.config/opencode/plugins/harness-memory/index.ts"

  remove_opencode_wiring_json "$cfg"
  rm -f "$plugin"
  log "Removed OpenCode global memory plugin file: $plugin"
}

uninstall_cursor_wiring() {
  local hooks_json="${HOME}/.cursor/hooks.json"
  local mcp_json="${HOME}/.cursor/mcp.json"
  local tmp
  if [ -f "$hooks_json" ]; then
    tmp="$(mktemp)"
    if jq '
      .hooks = (.hooks // {})
      | .hooks.beforeSubmitPrompt = ((.hooks.beforeSubmitPrompt // []) | map(select(((.command // "") | contains("memory-cursor-event.sh")) | not)))
      | .hooks.afterMCPExecution = ((.hooks.afterMCPExecution // []) | map(select(((.command // "") | contains("memory-cursor-event.sh")) | not)))
      | .hooks.afterShellExecution = ((.hooks.afterShellExecution // []) | map(select(((.command // "") | contains("memory-cursor-event.sh")) | not)))
      | .hooks.afterFileEdit = ((.hooks.afterFileEdit // []) | map(select(((.command // "") | contains("memory-cursor-event.sh")) | not)))
      | .hooks.stop = ((.hooks.stop // []) | map(select(((.command // "") | contains("memory-cursor-event.sh")) | not)))
    ' "$hooks_json" >"$tmp" 2>/dev/null; then
      mv "$tmp" "$hooks_json"
      log "Removed Cursor memory hooks from: $hooks_json"
    else
      rm -f "$tmp"
      warn "Could not parse Cursor hooks JSON for cleanup: $hooks_json"
    fi
  fi

  rm -f "${HOME}/.cursor/hooks/memory-cursor-event.sh"
  log "Removed Cursor memory hook script"

  if [ -f "$mcp_json" ]; then
    tmp="$(mktemp)"
    if jq 'if has("mcpServers") then .mcpServers |= del(.harness) else . end' "$mcp_json" >"$tmp" 2>/dev/null; then
      mv "$tmp" "$mcp_json"
      log "Removed Cursor harness MCP wiring from: $mcp_json"
    else
      rm -f "$tmp"
      warn "Could not parse Cursor MCP JSON for cleanup: $mcp_json"
    fi
  fi
}

uninstall_antigravity_wiring() {
  log "Antigravity wiring cleanup: no project files to remove"
}

uninstall_impl() {
  if check_cmd bun; then
    HARNESS_MEM_CODEX_PROJECT_ROOT="$TARGET_DIR" \
      HARNESS_MEM_HOST="$MEM_HOST" \
      HARNESS_MEM_PORT="$MEM_PORT" \
      HARNESS_MEM_DB_PATH="$DB_PATH" \
      "$HARNESS_ROOT/scripts/harness-memd" stop --quiet >/dev/null 2>&1 || true
  fi

  if is_platform_enabled codex; then
    uninstall_codex_wiring
  fi
  if is_platform_enabled opencode; then
    uninstall_opencode_wiring
  fi
  if is_platform_enabled claude; then
    uninstall_claude_wiring
  fi
  if is_platform_enabled cursor; then
    uninstall_cursor_wiring
  fi
  if is_platform_enabled antigravity; then
    uninstall_antigravity_wiring
  fi

  rm -f "${STATE_DIR}/daemon.pid" "${STATE_DIR}/daemon.lock" "${STATE_DIR}/daemon.heartbeat"
  rm -rf "${STATE_DIR}/runtime"
  log "Removed runtime cache: ${STATE_DIR}/runtime"
  if [ "$PURGE_DB" -eq 1 ]; then
    rm -f "$DB_PATH"
    log "Purged DB: $DB_PATH"
  fi

  log "Uninstall complete (project=${TARGET_DIR}, platform=${PLATFORM})"
}

_check_shadow_metrics_gate() {
  # Query daemon shadow metrics and check promotion SLA.
  # Returns 0 if SLA met, 1 if not. Outputs reasons to stderr.
  local port="${HARNESS_MEM_PORT:-37888}"
  local token="${HARNESS_MEM_ADMIN_TOKEN:-}"
  local curl_opts=(-sf --max-time 5)
  if [ -n "$token" ]; then
    curl_opts+=(-H "x-harness-mem-token: ${token}")
  fi
  local shadow_json
  shadow_json="$(curl "${curl_opts[@]}" "http://127.0.0.1:${port}/v1/admin/shadow-metrics" 2>/dev/null)" || {
    warn "Cannot reach daemon at port ${port}. Is it running?"
    return 1
  }

  local managed_backend
  managed_backend="$(echo "$shadow_json" | jq -r '.items[0].managed_backend // empty' 2>/dev/null)"
  if [ -z "$managed_backend" ] || [ "$managed_backend" = "null" ]; then
    warn "Managed backend not initialized. Start daemon in hybrid mode first."
    return 1
  fi

  local shadow_reads shadow_match_rate managed_replications replication_failures
  shadow_reads="$(echo "$shadow_json" | jq -r '.items[0].shadow_metrics.shadow_reads // 0')"
  shadow_match_rate="$(echo "$shadow_json" | jq -r '.items[0].shadow_metrics.shadow_match_rate // 0')"
  managed_replications="$(echo "$shadow_json" | jq -r '.items[0].shadow_metrics.managed_replications // 0')"
  replication_failures="$(echo "$shadow_json" | jq -r '.items[0].shadow_metrics.replication_failures // 0')"

  local gate_pass=true
  local reasons=""

  # Gate 1: minimum shadow reads >= 100
  if [ "$shadow_reads" -lt 100 ] 2>/dev/null; then
    gate_pass=false
    reasons="${reasons}  - Insufficient shadow reads: ${shadow_reads}/100\n"
  fi

  # Gate 2: shadow match rate >= 95%
  local match_pct
  match_pct="$(echo "$shadow_match_rate * 100" | bc -l 2>/dev/null || echo "0")"
  local match_check
  match_check="$(echo "$shadow_match_rate < 0.95" | bc -l 2>/dev/null || echo "1")"
  if [ "$match_check" = "1" ]; then
    gate_pass=false
    reasons="${reasons}  - Shadow match rate too low: ${match_pct}% (need >=95%)\n"
  fi

  # Gate 3: replication failure rate < 1%
  local total_rep failure_rate failure_check
  total_rep="$(( managed_replications + replication_failures ))"
  if [ "$total_rep" -gt 0 ] 2>/dev/null; then
    failure_rate="$(echo "scale=4; $replication_failures / $total_rep" | bc -l 2>/dev/null || echo "0")"
    failure_check="$(echo "$failure_rate > 0.01" | bc -l 2>/dev/null || echo "0")"
    if [ "$failure_check" = "1" ]; then
      gate_pass=false
      local failure_pct
      failure_pct="$(echo "$failure_rate * 100" | bc -l 2>/dev/null || echo "0")"
      reasons="${reasons}  - Replication failure rate too high: ${failure_pct}% (need <1%)\n"
    fi
  fi

  if [ "$gate_pass" = "false" ]; then
    warn "Shadow metrics gate FAILED. Promotion denied."
    warn "Current metrics:"
    warn "  shadow_reads:        ${shadow_reads}"
    warn "  shadow_match_rate:   ${match_pct}%"
    warn "  replications:        ${managed_replications}"
    warn "  replication_failures: ${replication_failures}"
    warn ""
    warn "Reasons:"
    printf "$reasons" >&2
    return 1
  fi

  log "Shadow metrics gate PASSED."
  log "  shadow_reads:        ${shadow_reads}"
  log "  shadow_match_rate:   ${match_pct}%"
  log "  replications:        ${managed_replications}"
  log "  replication_failures: ${replication_failures}"
  return 0
}

promote_impl() {
  ensure_config
  local current_backend
  current_backend="$(read_backend_mode)"

  case "$current_backend" in
    local)
      log "Current backend mode: local"
      log "Promoting to hybrid (shadow phase)..."
      write_backend_mode "hybrid"
      log "Backend mode set to: hybrid"
      log ""
      log "Next steps:"
      log "  1. Configure managed endpoint: set managed.endpoint in ${CONFIG_PATH}"
      log "  2. Restart daemon: scripts/harness-memd restart"
      log "  3. Run proof-pack to verify: scripts/harness-mem-proof-pack.sh"
      log "  4. Once shadow metrics pass SLA, run: harness-mem promote (again)"
      ;;
    hybrid)
      log "Current backend mode: hybrid"
      local managed_ep
      managed_ep="$(read_managed_endpoint)"
      if [ -z "$managed_ep" ]; then
        warn "Cannot promote to managed: managed endpoint not configured"
        warn "Set managed.endpoint in ${CONFIG_PATH}"
        return 1
      fi

      # Shadow metrics gate: must pass SLA before promotion
      log "Checking shadow metrics gate..."
      if ! _check_shadow_metrics_gate; then
        warn ""
        warn "Promotion blocked: shadow metrics SLA not met."
        warn "Continue running in hybrid mode to accumulate metrics."
        warn "Required: shadow_reads >= 100, match_rate >= 95%, repl_failure < 1%"
        return 1
      fi

      log "Promoting to managed..."
      write_backend_mode "managed"
      log "Backend mode set to: managed"
      log ""
      log "Next steps:"
      log "  1. Restart daemon: scripts/harness-memd restart"
      log "  2. Run proof-pack to verify: scripts/harness-mem-proof-pack.sh"
      log "  3. If issues arise, run: harness-mem rollback"
      ;;
    managed)
      log "Already at managed backend mode. No further promotion available."
      ;;
  esac
}

rollback_impl() {
  ensure_config
  local current_backend
  current_backend="$(read_backend_mode)"

  case "$current_backend" in
    local)
      log "Already at local backend mode. Nothing to rollback."
      ;;
    hybrid|managed)
      log "Current backend mode: ${current_backend}"
      log "Rolling back to local..."
      write_backend_mode "local"
      log "Backend mode set to: local"
      log ""
      log "Next steps:"
      log "  1. Restart daemon: scripts/harness-memd restart"
      log "  2. Run doctor to verify: harness-mem doctor"
      ;;
  esac
}

main() {
  local command="${1:-help}"
  shift || true

  parse_options "$@"
  normalize_ui_lang
  if should_prompt_platform_selection "$command"; then
    prompt_language_selection
    prompt_platform_selection
    SETUP_INTERACTIVE_PROMPT_USED=1
  fi
  if should_prompt_setup_migration_selection "$command"; then
    prompt_setup_migration_selection
  fi
  if should_prompt_setup_auto_update_selection "$command"; then
    prompt_setup_auto_update_selection
  fi

  TARGET_DIR="$(abs_dir "$TARGET_DIR")"

  if should_use_stable_runtime_root; then
    sync_to_stable_runtime_root
  fi

  validate_platform_selection
  maybe_auto_update "$command"

  case "$command" in
    setup)
      setup_impl
      ;;
    doctor)
      doctor_impl
      ;;
    smoke)
      ensure_dependencies
      ensure_mcp_runtime
      run_smoke
      ;;
    versions)
      versions_impl
      ;;
    uninstall)
      uninstall_impl
      ;;
    import-claude-mem)
      import_claude_mem_impl
      ;;
    verify-import)
      verify_import_impl
      ;;
    cutover-claude-mem)
      cutover_claude_mem_impl
      ;;
    migrate-from-claude-mem)
      migrate_from_claude_mem_impl
      ;;
    rollback-claude-mem)
      rollback_claude_mem_impl
      ;;
    promote)
      promote_impl
      ;;
    rollback)
      rollback_impl
      ;;
    help|-h|--help)
      usage
      ;;
    *)
      fail "Unknown command: $command"
      ;;
  esac
}

main "$@"
